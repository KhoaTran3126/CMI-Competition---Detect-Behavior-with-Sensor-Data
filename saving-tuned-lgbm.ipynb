{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce03e5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:40:52.757061Z",
     "iopub.status.busy": "2025-06-14T02:40:52.756723Z",
     "iopub.status.idle": "2025-06-14T02:41:05.068171Z",
     "shell.execute_reply": "2025-06-14T02:41:05.067115Z"
    },
    "papermill": {
     "duration": 12.318802,
     "end_time": "2025-06-14T02:41:05.070384",
     "exception": false,
     "start_time": "2025-06-14T02:40:52.751582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib \n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import optuna\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import kaggle_evaluation.cmi_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99a86e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:05.079288Z",
     "iopub.status.busy": "2025-06-14T02:41:05.078581Z",
     "iopub.status.idle": "2025-06-14T02:41:05.882732Z",
     "shell.execute_reply": "2025-06-14T02:41:05.881647Z"
    },
    "papermill": {
     "duration": 0.81028,
     "end_time": "2025-06-14T02:41:05.884548",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.074268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 3126\n",
    "\n",
    "train = pd.read_csv(\"/kaggle/input/sequence-level-broad-summary-features/train_features.csv\")\n",
    "train_demo = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\")\n",
    "test  = pl.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\")\n",
    "test_demo  = pl.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\")\n",
    "\n",
    "label_encoder = joblib.load(\"/kaggle/input/sequence-level-broad-summary-features/label_encoder.joblib\")\n",
    "\n",
    "feature_cols = [col for col in train.columns \n",
    "                if col not in ['sequence_id', 'target', 'gesture', 'subject']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde41d67",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:05.893447Z",
     "iopub.status.busy": "2025-06-14T02:41:05.892144Z",
     "iopub.status.idle": "2025-06-14T02:41:05.921323Z",
     "shell.execute_reply": "2025-06-14T02:41:05.920222Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.035337,
     "end_time": "2025-06-14T02:41:05.923116",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.887779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_sequence_summary_features(df, demographics_df=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive features from sensor sequences\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Group by sequence_id to create sequence-level features\n",
    "    for seq_id, group in df.groupby('sequence_id'):\n",
    "        seq_features = {'sequence_id': seq_id}\n",
    "        columns = set(group.columns)\n",
    "        \n",
    "        # Basic sequence info\n",
    "        seq_features['sequence_length'] = len(group)\n",
    "        seq_features['subject'] = group['subject'].iloc[0]\n",
    "        \n",
    "        # Add demographics if available\n",
    "        if (demographics_df is not None) and (not demographics_df.empty):\n",
    "            subject_demo = demographics_df[ demographics_df['subject'] == seq_features['subject'] ]\n",
    "            if not subject_demo.empty:\n",
    "                seq_features['adult_child'] = subject_demo['adult_child'].iloc[0]\n",
    "                seq_features['age'] = subject_demo['age'].iloc[0]\n",
    "                seq_features['sex'] = subject_demo['sex'].iloc[0]\n",
    "                seq_features['handedness'] = subject_demo['handedness'].iloc[0]\n",
    "                seq_features['height_cm']  = subject_demo['height_cm'].iloc[0]\n",
    "                seq_features['shoulder_to_wrist_cm'] = subject_demo['shoulder_to_wrist_cm'].iloc[0]\n",
    "                seq_features['elbow_to_wrist_cm']    = subject_demo['elbow_to_wrist_cm'].iloc[0]\n",
    "            else:\n",
    "                # Set default values if demographics not found\n",
    "                seq_features['adult_child'] = -1\n",
    "                seq_features['age'] = -1\n",
    "                seq_features['sex'] = -1\n",
    "                seq_features['handedness'] = -1\n",
    "                seq_features['height_cm'] = -1\n",
    "                seq_features['shoulder_to_wrist_cm'] = -1\n",
    "                seq_features['elbow_to_wrist_cm'] = -1\n",
    "        else:\n",
    "            # Set default values if demographics not available\n",
    "            seq_features['adult_child'] = -1\n",
    "            seq_features['age'] = -1\n",
    "            seq_features['sex'] = -1\n",
    "            seq_features['handedness'] = -1\n",
    "            seq_features['height_cm'] = -1\n",
    "            seq_features['shoulder_to_wrist_cm'] = -1\n",
    "            seq_features['elbow_to_wrist_cm'] = -1\n",
    "        \n",
    "        # Behavior phase encoding (if available)\n",
    "        if 'behavior' in columns:\n",
    "            behavior_counts = group['behavior'].value_counts()\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = behavior_counts.get(behavior, 0)\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = behavior_counts.get(behavior, 0) / len(group)\n",
    "        else:\n",
    "            # Set default values if behavior column is not available\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = 0\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = 0\n",
    "        \n",
    "        # Statistical features for each sensor type\n",
    "        sensor_groups = {\n",
    "            'acc': ['acc_x', 'acc_y', 'acc_z'],\n",
    "            'rot': ['rot_w', 'rot_x', 'rot_y', 'rot_z'],\n",
    "            'thm': [\"thm_1\", \"thm_2\", \"thm_3\", \"thm_4\", \"thm_5\"],\n",
    "            'tof': [f\"tof_{i}_v{j}\" for i in range(1,6) for j in range(0,64)]\n",
    "        }\n",
    "        \n",
    "        for sensor_type, cols in sensor_groups.items():\n",
    "            available_cols = [col for col in cols if col in columns]\n",
    "            if available_cols:\n",
    "                sensor_data = group[available_cols].values        \n",
    "                # Basic statistics\n",
    "                seq_features[f'{sensor_type}_mean'] = np.mean(sensor_data)\n",
    "                seq_features[f'{sensor_type}_std']  = np.std(sensor_data)\n",
    "                seq_features[f'{sensor_type}_min']  = np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_max']  = np.max(sensor_data)\n",
    "                seq_features[f'{sensor_type}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_median'] = np.median(sensor_data)\n",
    "                \n",
    "                # Percentiles\n",
    "                seq_features[f'{sensor_type}_q25'] = np.percentile(sensor_data, 25)\n",
    "                seq_features[f'{sensor_type}_q75'] = np.percentile(sensor_data, 75)\n",
    "                seq_features[f'{sensor_type}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "                # Signal characteristics\n",
    "                seq_features[f'{sensor_type}_energy'] = np.sum(sensor_data**2)\n",
    "                seq_features[f'{sensor_type}_rms'] = np.sqrt(np.mean(sensor_data**2))\n",
    "\n",
    "                if sensor_type != \"tof\":\n",
    "                    for col in available_cols:\n",
    "                        sensor_data = group[col].values\n",
    "                        seq_features[f'{col}_mean'] = np.mean(sensor_data)\n",
    "                        seq_features[f'{col}_std']  = np.std(sensor_data)\n",
    "                        seq_features[f'{col}_min']  = np.min(sensor_data)\n",
    "                        seq_features[f'{col}_max']  = np.max(sensor_data)\n",
    "                        seq_features[f'{col}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                        seq_features[f'{col}_median'] = np.median(sensor_data)\n",
    "                    \n",
    "                        # Percentiles\n",
    "                        seq_features[f'{col}_q25'] = np.percentile(sensor_data, 25)\n",
    "                        seq_features[f'{col}_q75'] = np.percentile(sensor_data, 75)\n",
    "                        seq_features[f'{col}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "        # Specific features for IMU data (acceleration and rotation)\n",
    "        if all(col in columns for col in ['acc_x', 'acc_y', 'acc_z']):\n",
    "            acc_data = group[['acc_x', 'acc_y', 'acc_z']].values\n",
    "            # Acceleration features\n",
    "            acc_magnitude = np.sqrt(np.sum(acc_data**2, axis=1))\n",
    "            jerk = np.nan_to_num(np.diff(acc_magnitude), nan=-666)\n",
    "            seq_features['jerk_mean'] = np.mean(jerk)\n",
    "            seq_features['jerk_std'] = np.std(jerk)\n",
    "            seq_features['acc_magnitude_mean'] = np.mean(acc_magnitude)\n",
    "            seq_features['acc_magnitude_std'] = np.std(acc_magnitude)\n",
    "            seq_features['acc_magnitude_max'] = np.max(acc_magnitude)\n",
    "            seq_features['acc_height_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['height_cm'], 1)\n",
    "            seq_features['acc_shoulder_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['shoulder_to_wrist_cm'], 1)\n",
    "            seq_features['acc_elbow_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['elbow_to_wrist_cm'], 1)\n",
    "            seq_features['acc_xy_corr'] = spearmanr(group['acc_x'], group['acc_y'], nan_policy='omit').statistic\n",
    "            seq_features['acc_yz_corr'] = spearmanr(group['acc_y'], group['acc_z'], nan_policy='omit').statistic\n",
    "            seq_features['acc_xz_corr'] = spearmanr(group['acc_x'], group['acc_z'], nan_policy='omit').statistic\n",
    "            seq_features[\"acc_x_cumsum\"] = np.sum(group[\"acc_x\"])\n",
    "            seq_features[\"acc_y_cumsum\"] = np.sum(group[\"acc_y\"])\n",
    "            seq_features[\"acc_z_cumsum\"] = np.sum(group[\"acc_z\"])\n",
    "            \n",
    "        # Rotational features\n",
    "        rot_angle = 2*np.arccos(np.clip(group[\"rot_w\"].values, -1.0, 1.0))\n",
    "        angular_velocity = np.nan_to_num(np.diff(rot_angle), nan=-666)\n",
    "        angular_acceleration = np.nan_to_num(np.diff(angular_velocity), nan=-666)\n",
    "        seq_features['rot_wx_corr'] = np.nan_to_num(spearmanr(group['rot_w'], group['rot_x'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['rot_wy_corr'] = np.nan_to_num(spearmanr(group['rot_w'], group['rot_y'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['rot_wz_corr'] = np.nan_to_num(spearmanr(group['rot_w'], group['rot_z'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['rot_xy_corr'] = np.nan_to_num(spearmanr(group['rot_x'], group['rot_y'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['rot_xz_corr'] = np.nan_to_num(spearmanr(group['rot_x'], group['rot_z'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['rot_yz_corr'] = np.nan_to_num(spearmanr(group['rot_y'], group['rot_z'], nan_policy='omit').statistic, nan=-666)\n",
    "        seq_features['angular_velocity_mean'] = np.mean(angular_velocity)\n",
    "        seq_features['angular_velocity_std'] = np.std(angular_velocity)\n",
    "        seq_features['angular_accel_mean'] = np.mean(angular_acceleration)\n",
    "        seq_features['angular_accel_std'] = np.std(angular_acceleration)\n",
    "        seq_features[\"rot_angle_cumsum\"] = np.sum(rot_angle)\n",
    "        seq_features[\"rot_angle_mean\"] = np.mean(rot_angle)\n",
    "        seq_features[\"rot_angle_median\"] = np.median(rot_angle)\n",
    "        seq_features[\"rot_angle_std\"]  = np.std(rot_angle)\n",
    "        seq_features[\"rot_angle_min\"]  = np.min(rot_angle)    \n",
    "        seq_features[\"rot_angle_max\"]  = np.max(rot_angle)\n",
    "        seq_features[\"rot_angle_range\"]  = np.max(rot_angle) - np.min(rot_angle)\n",
    "        seq_features[\"rot_angle_q25\"] = np.percentile(rot_angle, 25)\n",
    "        seq_features[\"rot_angle_q75\"] = np.percentile(rot_angle, 75)\n",
    "        seq_features[\"rot_angle_iqr\"] = np.percentile(rot_angle, 75) - np.percentile(rot_angle, 25)                \n",
    "        seq_features['rot_angle_energy'] = np.sum(rot_angle**2)\n",
    "        seq_features['rot_angle_rms'] = np.sqrt(np.mean(rot_angle**2))\n",
    "        \n",
    "        # Add target if available\n",
    "        if 'encoded_gesture' in columns:\n",
    "            seq_features['target'] = group['encoded_gesture'].iloc[0]\n",
    "            seq_features['gesture'] = group['gesture'].iloc[0]\n",
    "        \n",
    "        features.append(seq_features)\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d4e2e3",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:05.931054Z",
     "iopub.status.busy": "2025-06-14T02:41:05.930694Z",
     "iopub.status.idle": "2025-06-14T02:41:05.940757Z",
     "shell.execute_reply": "2025-06-14T02:41:05.939744Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016014,
     "end_time": "2025-06-14T02:41:05.942428",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.926414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        \n",
    "        f1_binary = f1_score(y_true_bin, y_pred_bin, pos_label=True, zero_division=0, average='binary')\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        f1_macro = f1_score(y_true_mc, y_pred_mc, average='macro', zero_division=0)\n",
    "\n",
    "        return f1_binary, f1_macro, (f1_binary+f1_macro)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1798f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:05.949930Z",
     "iopub.status.busy": "2025-06-14T02:41:05.949554Z",
     "iopub.status.idle": "2025-06-14T02:41:05.956637Z",
     "shell.execute_reply": "2025-06-14T02:41:05.955608Z"
    },
    "papermill": {
     "duration": 0.012923,
     "end_time": "2025-06-14T02:41:05.958456",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.945533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F1_score(y_val, y_pred, lbl_encoder, choice=\"weighted_score\"):\n",
    "    metric = CompetitionMetric()\n",
    "    y_val  = pd.DataFrame({'id':range(len(y_val)), \n",
    "                           'gesture':y_val})\n",
    "    y_pred = pd.DataFrame({'id':range(len(y_pred)), \n",
    "                           'gesture':y_pred})\n",
    "\n",
    "    ## Convert numeric labels to original descriptions\n",
    "    y_val[\"gesture\"]  = lbl_encoder.inverse_transform(y_val[\"gesture\"])\n",
    "    y_pred[\"gesture\"] = lbl_encoder.inverse_transform(y_pred[\"gesture\"])\n",
    "\n",
    "    ## Computes score\n",
    "    binary, macro, weighted_score = metric.calculate_hierarchical_f1(y_val, y_pred)\n",
    "\n",
    "    ## Returns result\n",
    "    if choice==\"binary\": return binary\n",
    "    elif choice==\"macro\": return macro\n",
    "    elif choice==\"weighted_score\": return weighted_score\n",
    "    else: return (binary, macro, weighted_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222a43b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:05.965902Z",
     "iopub.status.busy": "2025-06-14T02:41:05.965564Z",
     "iopub.status.idle": "2025-06-14T02:41:05.994714Z",
     "shell.execute_reply": "2025-06-14T02:41:05.993454Z"
    },
    "papermill": {
     "duration": 0.035067,
     "end_time": "2025-06-14T02:41:05.996598",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.961531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train[feature_cols]\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fe3da2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:06.004196Z",
     "iopub.status.busy": "2025-06-14T02:41:06.003795Z",
     "iopub.status.idle": "2025-06-14T02:41:06.013274Z",
     "shell.execute_reply": "2025-06-14T02:41:06.012232Z"
    },
    "papermill": {
     "duration": 0.015281,
     "end_time": "2025-06-14T02:41:06.014921",
     "exception": false,
     "start_time": "2025-06-14T02:41:05.999640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cv_evaluate(model, model_kind, X, y, lbl_encoder, n_splits=5, \n",
    "                random_state=SEED, stopping_rounds=100, min_delta=.0005):\n",
    "    skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    oof_preds = np.zeros_like(y)\n",
    "    binary_scores   = []\n",
    "    macro_scores    = []\n",
    "    weighted_scores = []\n",
    "    history = {}\n",
    "    \n",
    "    for fold_num,(train_fold, val_fold) in enumerate(skfold.split(X, y)):\n",
    "        print(f\"\\nFold {fold_num + 1}/{n_splits}\")\n",
    "        X_train, y_train = X.iloc[train_fold], y[train_fold]\n",
    "        X_val, y_val     = X.iloc[val_fold], y[val_fold]\n",
    "\n",
    "        cloned_model = clone(model)\n",
    "\n",
    "        if model_kind==\"lgbm\":\n",
    "            cloned_model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                callbacks=[lightgbm.early_stopping(stopping_rounds=stopping_rounds, min_delta=min_delta)]\n",
    "            )\n",
    "        else:\n",
    "            cloned_model.fit(X_train, y_train)\n",
    "        ## Stores out-of-fold predictions\n",
    "        y_pred = cloned_model.predict(X_val)\n",
    "        oof_preds[val_fold] = y_pred\n",
    "        \n",
    "        ## Store cv scores\n",
    "        binary, macro, weighted_score = F1_score(y_val, y_pred, lbl_encoder, choice=None)\n",
    "        binary_scores.append(binary)\n",
    "        macro_scores.append(macro)\n",
    "        weighted_scores.append(weighted_score)\n",
    "    \n",
    "    ## Store cv results inside dict\n",
    "    history[\"oof_preds\"] = oof_preds\n",
    "    history[\"binary_scores\"] = binary_scores\n",
    "    history[\"macro_scores\"]  = macro_scores\n",
    "    history[\"weighted_scores\"] = weighted_scores\n",
    "\n",
    "    ## Store oof prediction scores inside dict\n",
    "    binary, macro, weighted_score = F1_score(y, oof_preds, lbl_encoder, choice=None)\n",
    "    history[\"full_binary_score\"] = binary\n",
    "    history[\"full_macro_score\"] = macro\n",
    "    history[\"full_weighted_score\"] = weighted_score\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e70a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:06.022099Z",
     "iopub.status.busy": "2025-06-14T02:41:06.021802Z",
     "iopub.status.idle": "2025-06-14T02:41:06.028211Z",
     "shell.execute_reply": "2025-06-14T02:41:06.027007Z"
    },
    "papermill": {
     "duration": 0.01179,
     "end_time": "2025-06-14T02:41:06.029807",
     "exception": false,
     "start_time": "2025-06-14T02:41:06.018017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 1601,\n",
    "    'learning_rate': 0.012502527035230948,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 56,\n",
    "    'min_child_samples': 70,\n",
    "    'subsample': 0.819484245856843,\n",
    "    'colsample_bytree': 0.8043769543397135,\n",
    "    'reg_lambda': 0.0031523588243255293,\n",
    "    'reg_alpha': 3.094663101246672e-07\n",
    "}\n",
    "params[\"class_weight\"] = \"balanced\"\n",
    "params[\"objective\"] = \"multiclass\"\n",
    "params[\"n_jobs\"] = -1\n",
    "params[\"verbose\"] = -1\n",
    "params[\"random_state\"] = SEED\n",
    "stopping_rounds = 100\n",
    "min_delta = 0.0006180506283718214\n",
    "\n",
    "tuned_lgbm = LGBMClassifier(**params)\n",
    "\n",
    "# tuned_lgbm_history =  cv_evaluate(tuned_lgbm, \"lgbm\", X, y, label_encoder, \n",
    "#                                   n_splits=5, random_state=SEED, stopping_rounds=stopping_rounds, min_delta=min_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a26ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:41:06.037237Z",
     "iopub.status.busy": "2025-06-14T02:41:06.036880Z",
     "iopub.status.idle": "2025-06-14T02:51:32.505161Z",
     "shell.execute_reply": "2025-06-14T02:51:32.503903Z"
    },
    "papermill": {
     "duration": 626.477825,
     "end_time": "2025-06-14T02:51:32.510734",
     "exception": false,
     "start_time": "2025-06-14T02:41:06.032909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.8043769543397135,\n",
       "               learning_rate=0.012502527035230948, max_depth=10,\n",
       "               min_child_samples=70, n_estimators=1601, n_jobs=-1,\n",
       "               num_leaves=56, objective=&#x27;multiclass&#x27;, random_state=3126,\n",
       "               reg_alpha=3.094663101246672e-07,\n",
       "               reg_lambda=0.0031523588243255293, subsample=0.819484245856843,\n",
       "               verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.8043769543397135,\n",
       "               learning_rate=0.012502527035230948, max_depth=10,\n",
       "               min_child_samples=70, n_estimators=1601, n_jobs=-1,\n",
       "               num_leaves=56, objective=&#x27;multiclass&#x27;, random_state=3126,\n",
       "               reg_alpha=3.094663101246672e-07,\n",
       "               reg_lambda=0.0031523588243255293, subsample=0.819484245856843,\n",
       "               verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.8043769543397135,\n",
       "               learning_rate=0.012502527035230948, max_depth=10,\n",
       "               min_child_samples=70, n_estimators=1601, n_jobs=-1,\n",
       "               num_leaves=56, objective='multiclass', random_state=3126,\n",
       "               reg_alpha=3.094663101246672e-07,\n",
       "               reg_lambda=0.0031523588243255293, subsample=0.819484245856843,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_lgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d90ea1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T02:51:32.518800Z",
     "iopub.status.busy": "2025-06-14T02:51:32.518476Z",
     "iopub.status.idle": "2025-06-14T02:51:35.794744Z",
     "shell.execute_reply": "2025-06-14T02:51:35.793625Z"
    },
    "papermill": {
     "duration": 3.282378,
     "end_time": "2025-06-14T02:51:35.796541",
     "exception": false,
     "start_time": "2025-06-14T02:51:32.514163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuned_lgbm_params.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Saves lgbm model\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
    "joblib.dump(tuned_lgbm, 'tuned_lgbm.joblib')\n",
    "joblib.dump(params, \"tuned_lgbm_params.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "isSourceIdPinned": false,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 244990358,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 245318423,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 650.952016,
   "end_time": "2025-06-14T02:51:37.024624",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-14T02:40:46.072608",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
