{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013cb8c5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:03.213331Z",
     "iopub.status.busy": "2025-06-20T18:13:03.212717Z",
     "iopub.status.idle": "2025-06-20T18:13:10.693166Z",
     "shell.execute_reply": "2025-06-20T18:13:10.692577Z"
    },
    "papermill": {
     "duration": 7.487528,
     "end_time": "2025-06-20T18:13:10.694504",
     "exception": false,
     "start_time": "2025-06-20T18:13:03.206976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7028d191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:10.704262Z",
     "iopub.status.busy": "2025-06-20T18:13:10.703948Z",
     "iopub.status.idle": "2025-06-20T18:13:10.788701Z",
     "shell.execute_reply": "2025-06-20T18:13:10.788130Z"
    },
    "papermill": {
     "duration": 0.090752,
     "end_time": "2025-06-20T18:13:10.789868",
     "exception": false,
     "start_time": "2025-06-20T18:13:10.699116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95\n",
    "PAD_LEN = 127\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4\n",
    "EPOCHS = 300\n",
    "PATIENCE = 15\n",
    "SEED = 3126\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6962580c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:10.799275Z",
     "iopub.status.busy": "2025-06-20T18:13:10.799059Z",
     "iopub.status.idle": "2025-06-20T18:13:10.873189Z",
     "shell.execute_reply": "2025-06-20T18:13:10.872658Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.080003,
     "end_time": "2025-06-20T18:13:10.874213",
     "exception": false,
     "start_time": "2025-06-20T18:13:10.794210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        \n",
    "        f1_binary = f1_score(y_true_bin, y_pred_bin, pos_label=True, zero_division=0, average='binary')\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        f1_macro = f1_score(y_true_mc, y_pred_mc, average='macro', zero_division=0)\n",
    "\n",
    "        return f1_binary, f1_macro, (f1_binary+f1_macro)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a23ecb7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:10.882868Z",
     "iopub.status.busy": "2025-06-20T18:13:10.882653Z",
     "iopub.status.idle": "2025-06-20T18:13:10.887047Z",
     "shell.execute_reply": "2025-06-20T18:13:10.886557Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.00983,
     "end_time": "2025-06-20T18:13:10.888044",
     "exception": false,
     "start_time": "2025-06-20T18:13:10.878214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F1_score(y_val, y_pred, lbl_encoder, choice=\"weighted\"):\n",
    "    metric = CompetitionMetric()\n",
    "    y_val  = pd.DataFrame({'id':range(len(y_val)), \n",
    "                           'gesture':y_val})\n",
    "    y_pred = pd.DataFrame({'id':range(len(y_pred)), \n",
    "                           'gesture':y_pred})\n",
    "\n",
    "    ## Convert numeric labels to original descriptions\n",
    "    y_val[\"gesture\"]  = lbl_encoder.inverse_transform(y_val[\"gesture\"])\n",
    "    y_pred[\"gesture\"] = lbl_encoder.inverse_transform(y_pred[\"gesture\"])\n",
    "\n",
    "    ## Computes score\n",
    "    binary, macro, weighted = metric.calculate_hierarchical_f1(y_val, y_pred)\n",
    "\n",
    "    ## Returns result\n",
    "    if choice==\"binary\": return binary\n",
    "    elif choice==\"macro\": return macro\n",
    "    elif choice==\"weighted\": return weighted\n",
    "    else: return (binary, macro, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318db94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:10.896579Z",
     "iopub.status.busy": "2025-06-20T18:13:10.896327Z",
     "iopub.status.idle": "2025-06-20T18:13:10.904791Z",
     "shell.execute_reply": "2025-06-20T18:13:10.904293Z"
    },
    "papermill": {
     "duration": 0.013751,
     "end_time": "2025-06-20T18:13:10.905717",
     "exception": false,
     "start_time": "2025-06-20T18:13:10.891966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_all(seed=3126):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "seed_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd45e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:10.914157Z",
     "iopub.status.busy": "2025-06-20T18:13:10.913972Z",
     "iopub.status.idle": "2025-06-20T18:13:12.876889Z",
     "shell.execute_reply": "2025-06-20T18:13:12.876312Z"
    },
    "papermill": {
     "duration": 1.968591,
     "end_time": "2025-06-20T18:13:12.878134",
     "exception": false,
     "start_time": "2025-06-20T18:13:10.909543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DIR = \"/kaggle/input/cmi-detect-behavior-with-sensor-data\"\n",
    "\n",
    "label_encoder = joblib.load(\"/kaggle/input/cmi-label-encoder/label_encoder.joblib\")\n",
    "standard_scaler = joblib.load(\"/kaggle/input/custom-tensor-data-v1/StandardScaler.joblib\")\n",
    "X = torch.load(\"/kaggle/input/custom-tensor-data-v1/X.pt\")\n",
    "y_int = np.load(\"/kaggle/input/custom-tensor-data-v1/y_int.npy\")\n",
    "y_ohe = torch.load(\"/kaggle/input/custom-tensor-data-v1/y.pt\")\n",
    "\n",
    "imu_cols = joblib.load(\"/kaggle/input/custom-tensor-data-v1/imu_cols.joblib\")\n",
    "thm_tof_cols = joblib.load(\"/kaggle/input/custom-tensor-data-v1/thm_tof_cols.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3072538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.887560Z",
     "iopub.status.busy": "2025-06-20T18:13:12.887113Z",
     "iopub.status.idle": "2025-06-20T18:13:12.891345Z",
     "shell.execute_reply": "2025-06-20T18:13:12.890581Z"
    },
    "papermill": {
     "duration": 0.010005,
     "end_time": "2025-06-20T18:13:12.892461",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.882456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU Features:\n",
      "['acc_x', 'acc_y', 'acc_z', 'acc_x_diff', 'acc_y_diff', 'acc_z_diff', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'acc_mag', 'rot_angle', 'acc_mag_diff', 'rot_angle_diff']\n",
      "\n",
      "\n",
      "Thm+TOF Features:\n",
      "['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'thm_1_diff', 'thm_2_diff', 'thm_3_diff', 'thm_4_diff', 'thm_5_diff', 'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max', 'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max', 'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max']\n"
     ]
    }
   ],
   "source": [
    "print(\"IMU Features:\")\n",
    "print(imu_cols)\n",
    "print(\"\\n\\nThm+TOF Features:\")\n",
    "print(thm_tof_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0192eb0c",
   "metadata": {
    "papermill": {
     "duration": 0.003852,
     "end_time": "2025-06-20T18:13:12.900589",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.896737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cb01c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.909243Z",
     "iopub.status.busy": "2025-06-20T18:13:12.909066Z",
     "iopub.status.idle": "2025-06-20T18:13:12.915647Z",
     "shell.execute_reply": "2025-06-20T18:13:12.915004Z"
    },
    "papermill": {
     "duration": 0.012216,
     "end_time": "2025-06-20T18:13:12.916768",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.904552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualCoordinateAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Coordinate Attention adapted for 1D temporal sequences.\n",
    "    Input: (B, T, C)\n",
    "    Output: (B, T, C)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super(ResidualCoordinateAttention, self).__init__()\n",
    "        self.mid_channels = max(8, channels // reduction)\n",
    "        self.pos_embed_T = nn.Parameter(torch.randn(1, self.mid_channels, PAD_LEN))\n",
    "        self.gamma = nn.Parameter(torch.tensor(1.0))  # learnable scaling\n",
    "\n",
    "        # Temporal pooling to preserve time-dimension structure\n",
    "        self.conv1 = nn.Conv1d(channels, self.mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.mid_channels)\n",
    "        self.act = nn.SiLU()\n",
    "        \n",
    "        # Learn attention over time (coordinate)\n",
    "        self.attn_T = nn.Conv1d(self.mid_channels, 1, kernel_size=1, bias=False)\n",
    "        self.attn_C = nn.Conv1d(self.mid_channels, channels, kernel_size=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, T, C) â†’ (B, C, T)\n",
    "        x_perm = x.permute(0, 2, 1)\n",
    "        # (B, rC, T)\n",
    "        f = self.act(self.bn1(self.conv1(x_perm))) \n",
    "        f = f + self.pos_embed_T[:, :, :f.shape[-1]]\n",
    "        # (B, 1, T)\n",
    "        time_attn = self.sigmoid(self.attn_T(f)) \n",
    "        # (B, C, 1)\n",
    "        channel_attn = self.sigmoid(self.attn_C(f.mean(dim=2, keepdim=True))) \n",
    "        \n",
    "        out = x_perm + self.gamma * (x_perm * time_attn * channel_attn)  # (B, C, T)\n",
    "        return out.permute(0, 2, 1)  # Back to (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087d3603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.925978Z",
     "iopub.status.busy": "2025-06-20T18:13:12.925805Z",
     "iopub.status.idle": "2025-06-20T18:13:12.932518Z",
     "shell.execute_reply": "2025-06-20T18:13:12.931847Z"
    },
    "papermill": {
     "duration": 0.01238,
     "end_time": "2025-06-20T18:13:12.933573",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.921193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualSECNNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual CNN Block with Squeeze-and-Excitation (SE)\n",
    "    Input expected in (batch_size, timesteps, channels) format.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, pool_size=2, drop=0.3):\n",
    "        super(ResidualSECNNBlock, self).__init__()\n",
    "        # PyTorch Conv1D expects (batch_size, channels, timesteps)\n",
    "\n",
    "        ## CNN model\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.attention = ResidualCoordinateAttention(out_channels)\n",
    "\n",
    "        self.shortcut_proj = None\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut_proj = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, padding='same', bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.relu_final = nn.ReLU(inplace=True)\n",
    "        if pool_size is not None: \n",
    "            self.max_pool = nn.MaxPool1d(pool_size)\n",
    "        else: \n",
    "            self.max_pool = None\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x                                      # (B, T, C_in)\n",
    "        x_permuted = self.cnn(x.permute(0, 2, 1))         # (B, C_out, T)\n",
    "        x_attn = self.attention(x_permuted.permute(0, 2, 1)) # (B, T, C_out)\n",
    "\n",
    "        # Handle shortcut connection\n",
    "        if self.shortcut_proj:\n",
    "            shortcut = self.shortcut_proj(shortcut.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # Residual connection\n",
    "        x = self.relu_final(x_attn + shortcut)\n",
    "        if self.max_pool is not None:\n",
    "            x = self.max_pool(x.permute(0, 2, 1)).permute(0, 2, 1) # (B, T, C_out) -> (B, T//pool_size, C_out)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811054b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.942466Z",
     "iopub.status.busy": "2025-06-20T18:13:12.941952Z",
     "iopub.status.idle": "2025-06-20T18:13:12.946187Z",
     "shell.execute_reply": "2025-06-20T18:13:12.945706Z"
    },
    "papermill": {
     "duration": 0.009587,
     "end_time": "2025-06-20T18:13:12.947126",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.937539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention mechanism to weigh the importance of different timesteps.\n",
    "    Input expected in (batch_size, timesteps, features) format.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim):\n",
    "        super(MLPAttention, self).__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim//8),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(feature_dim//8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs shape: (B, T, C)\n",
    "        score = self.attn(inputs).squeeze(-1) # (B, T)\n",
    "        weights = F.softmax(score, dim=-1).unsqueeze(-1) # (B, T, 1)\n",
    "        context = (inputs * weights).sum(dim=1) # (B, T, C) -> (B, C)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ec2517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.956019Z",
     "iopub.status.busy": "2025-06-20T18:13:12.955851Z",
     "iopub.status.idle": "2025-06-20T18:13:12.965738Z",
     "shell.execute_reply": "2025-06-20T18:13:12.965081Z"
    },
    "papermill": {
     "duration": 0.01571,
     "end_time": "2025-06-20T18:13:12.966917",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.951207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoBranchModel(nn.Module):\n",
    "    def __init__(self, pad_len, imu_dim, thm_tof_dim, n_classes=18):\n",
    "        super(TwoBranchModel, self).__init__()\n",
    "        self.imu_dim = imu_dim\n",
    "        self.thm_tof_dim = thm_tof_dim\n",
    "        \n",
    "        # --- IMU Deep Branch ---\n",
    "        # (B, T, IMU dim) --> --> (B, T/4, 128)\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualSECNNBlock(imu_dim, 64, kernel_size=3, pool_size=2, drop=0.1), # Output shape: (B, T/2, 64)\n",
    "            ResidualSECNNBlock(64, 64, kernel_size=3, pool_size=None, drop=0.1), # Output shape: (B, T/2, 64)\n",
    "            ResidualSECNNBlock(64, 128, kernel_size=5, pool_size=2, drop=0.1) # Output shape: (B, T/4, 128)\n",
    "        )\n",
    "\n",
    "        # --- Thm/TOF Lighter Branch ---\n",
    "        # (B, T, Thm+TOF dim) --> (B, T/4, 128)\n",
    "        self.thm_tof_branch = nn.Sequential(\n",
    "            nn.Conv1d(thm_tof_dim, 64, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv1d(64, 64, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(64, 128, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2)  \n",
    "        )\n",
    "\n",
    "        # --- Merged Branch and Recurrent Layers ---\n",
    "        # Merged dimension: 128 (IMU) + 128 (Thm + TOF) = 256\n",
    "        merged_feature_dim = 128 + 128\n",
    "        self.lstm = nn.LSTM(merged_feature_dim, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "        self.gru  = nn.GRU(merged_feature_dim, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Output of bidirectional LSTM/GRU will be 2 * hidden_size\n",
    "        # (batch_size, timesteps_after_pooling, 2 * 128) = (batch_size, pad_len/4, 256)\n",
    "\n",
    "        # For x_merged path\n",
    "        self.gaussian_noise_std = 0.09 \n",
    "        self.dense = nn.Linear(merged_feature_dim, 16)\n",
    "        self.elu   = nn.ELU()\n",
    "        \n",
    "        # Concatenated features \n",
    "        # x_gru: (B, T, 256)\n",
    "        # x_lstm: (B, T, 256)\n",
    "        # x_merged: (B, T, 16)\n",
    "        self.concat_dropout = nn.Dropout(0.4)\n",
    "        self.attention_layer = MLPAttention(528)\n",
    "\n",
    "        # --- Classification Head ---\n",
    "        # After attention, shape is (B, 528)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(528, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x_imu     = inp[:, :, :self.imu_dim] # (B, T, IMU dim)\n",
    "        x_thm_tof = inp[:, :, self.imu_dim:] # (B, T, Thm + TOF dim)\n",
    "\n",
    "        # --- IMU Deep Branch ---\n",
    "        x_imu = self.imu_branch(x_imu) # (B, T/4, 128)\n",
    "\n",
    "        # --- TOF/Thermal Lighter Branch ---\n",
    "        x_thm_tof = self.thm_tof_branch(x_thm_tof.permute(0, 2, 1)) \n",
    "        x_thm_tof = x_thm_tof.permute(0, 2, 1) # (B, T/4, 128)\n",
    "\n",
    "        # --- Merge Branches ---\n",
    "        merged = torch.cat([x_imu, x_thm_tof], dim=-1) # (B, T/4, 256)\n",
    "\n",
    "        # --- Recurrent Layers ---\n",
    "        x_lstm, _ = self.lstm(merged) # (B, T/4, 256)\n",
    "        x_gru, _  = self.gru(merged)  # (B, T/4, 256)\n",
    "        \n",
    "        # x_merged path (gaussian noise)\n",
    "        if self.training: \n",
    "            x_merged = merged + torch.randn_like(merged)*self.gaussian_noise_std\n",
    "        else:\n",
    "            x_merged = merged\n",
    "        x_merged = self.elu(self.dense(x_merged)) # (B, T/4, 16)\n",
    "\n",
    "        # Concatenate outputs of all three paths\n",
    "        x = torch.cat([x_lstm, x_gru, x_merged], dim=-1) # (B, T/4, 256*2 + 16) = (B, T/4, 528)\n",
    "        x = self.concat_dropout(x)\n",
    "\n",
    "        # Attention layer\n",
    "        x = self.attention_layer(x) # Output: (B, 528)\n",
    "\n",
    "        # --- Classification Head ---\n",
    "        x = self.classifier(x)\n",
    "        out = self.output_layer(x) # (B, 18)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5495354",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.975558Z",
     "iopub.status.busy": "2025-06-20T18:13:12.975349Z",
     "iopub.status.idle": "2025-06-20T18:13:12.980550Z",
     "shell.execute_reply": "2025-06-20T18:13:12.979881Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010819,
     "end_time": "2025-06-20T18:13:12.981688",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.970869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model_weights(model:nn.Module):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv1d)):\n",
    "            nn.init.kaiming_uniform_(module.weight, nonlinearity=\"relu\")\n",
    "            \n",
    "        elif isinstance(module, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in module.named_parameters():\n",
    "                if 'weight_ih' in name: \n",
    "                    nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name: \n",
    "                    nn.init.orthogonal_(param.data) \n",
    "                elif 'bias_ih' in name or 'bias_hh' in name: \n",
    "                    nn.init.constant_(param.data, 0)\n",
    "                    if 'bias_ih' in name and isinstance(module, nn.LSTM):\n",
    "                        nn.init.constant_(param.data[module.hidden_size : 2 * module.hidden_size], 1.0)\n",
    "        \n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bed3afbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:12.990305Z",
     "iopub.status.busy": "2025-06-20T18:13:12.990139Z",
     "iopub.status.idle": "2025-06-20T18:13:12.995618Z",
     "shell.execute_reply": "2025-06-20T18:13:12.994933Z"
    },
    "papermill": {
     "duration": 0.010963,
     "end_time": "2025-06-20T18:13:12.996631",
     "exception": false,
     "start_time": "2025-06-20T18:13:12.985668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MixupDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, alpha: float = 0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (np.ndarray): Features (e.g., padded time series data).\n",
    "                            Expected shape (num_samples, timesteps, features).\n",
    "            y (np.ndarray): Labels (e.g., one-hot encoded or class indices).\n",
    "                            Expected shape (num_samples, num_classes) for one-hot,\n",
    "                            or (num_samples,) for class indices.\n",
    "            alpha (float): Alpha parameter for the Beta distribution used in Mixup.\n",
    "        \"\"\"\n",
    "        # Convert X and y to PyTorch tensors once\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32 if (y.ndim>1) else (torch.long)) # Use long for class indices\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data for Mixup.\n",
    "        \"\"\"\n",
    "        x, y = self.X[idx], self.y[idx]\n",
    "        \n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            rand_idx = np.random.randint(0, len(self.X))\n",
    "            x_rand, y_rand = self.X[rand_idx], self.y[rand_idx]\n",
    "            \n",
    "            x = lam * x + (1 - lam) * x_rand\n",
    "            y = lam * y + (1 - lam) * y_rand\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeaa3b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:13.005011Z",
     "iopub.status.busy": "2025-06-20T18:13:13.004821Z",
     "iopub.status.idle": "2025-06-20T18:13:13.008593Z",
     "shell.execute_reply": "2025-06-20T18:13:13.008043Z"
    },
    "papermill": {
     "duration": 0.009069,
     "end_time": "2025-06-20T18:13:13.009621",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.000552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_smoothing_loss(pred, target, smoothing=0.1):\n",
    "    \"\"\"Label smoothing loss\"\"\"\n",
    "    confidence = 1.0 - smoothing\n",
    "    log_probs = F.log_softmax(pred, dim=-1)\n",
    "    nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "    nll_loss = nll_loss.squeeze(1)\n",
    "    smooth_loss = -log_probs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad8d19",
   "metadata": {
    "papermill": {
     "duration": 0.003686,
     "end_time": "2025-06-20T18:13:13.017277",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.013591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c7ca0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:13.025679Z",
     "iopub.status.busy": "2025-06-20T18:13:13.025486Z",
     "iopub.status.idle": "2025-06-20T18:13:13.038614Z",
     "shell.execute_reply": "2025-06-20T18:13:13.038131Z"
    },
    "papermill": {
     "duration": 0.018411,
     "end_time": "2025-06-20T18:13:13.039577",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.021166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7044c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:13.048146Z",
     "iopub.status.busy": "2025-06-20T18:13:13.047815Z",
     "iopub.status.idle": "2025-06-20T18:13:13.401748Z",
     "shell.execute_reply": "2025-06-20T18:13:13.401162Z"
    },
    "papermill": {
     "duration": 0.359553,
     "end_time": "2025-06-20T18:13:13.403061",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.043508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X.numpy(), y_ohe.numpy(), \n",
    "        test_size=0.2, random_state=SEED, stratify=y_int\n",
    ")\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "\n",
    "cw_vals = compute_class_weight('balanced', \n",
    "                               classes=np.arange(len(label_encoder.classes_)),\n",
    "                               y=y_int)\n",
    "class_weights = torch.FloatTensor(cw_vals).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61582058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:13.412259Z",
     "iopub.status.busy": "2025-06-20T18:13:13.412045Z",
     "iopub.status.idle": "2025-06-20T18:13:13.492127Z",
     "shell.execute_reply": "2025-06-20T18:13:13.491514Z"
    },
    "papermill": {
     "duration": 0.086075,
     "end_time": "2025-06-20T18:13:13.493495",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.407420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_dataset = MixupDataset(X_train, y_train, alpha=MIXUP_ALPHA)\n",
    "val_dataset = MixupDataset(X_val, y_val, alpha=0.0)  \n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47bc20d",
   "metadata": {
    "papermill": {
     "duration": 0.003955,
     "end_time": "2025-06-20T18:13:13.501893",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.497938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8d97fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:13.510625Z",
     "iopub.status.busy": "2025-06-20T18:13:13.510427Z",
     "iopub.status.idle": "2025-06-20T18:13:18.244665Z",
     "shell.execute_reply": "2025-06-20T18:13:18.244103Z"
    },
    "papermill": {
     "duration": 4.740132,
     "end_time": "2025-06-20T18:13:18.246000",
     "exception": false,
     "start_time": "2025-06-20T18:13:13.505868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TwoBranchModel(PAD_LEN, len(imu_cols), len(thm_tof_cols)).to(DEVICE)\n",
    "init_model_weights(model)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR_INIT, weight_decay=WD)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5*steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67b70e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:18.255439Z",
     "iopub.status.busy": "2025-06-20T18:13:18.255092Z",
     "iopub.status.idle": "2025-06-20T18:13:18.259960Z",
     "shell.execute_reply": "2025-06-20T18:13:18.259280Z"
    },
    "papermill": {
     "duration": 0.010591,
     "end_time": "2025-06-20T18:13:18.261059",
     "exception": false,
     "start_time": "2025-06-20T18:13:18.250468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class F1EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_f1 = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, model, current_f1):\n",
    "        if current_f1 > self.best_f1:\n",
    "            self.best_f1 = current_f1\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"F1 EarlyStopping: {self.counter}/{self.patience}\\n\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e57de1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:18.269748Z",
     "iopub.status.busy": "2025-06-20T18:13:18.269551Z",
     "iopub.status.idle": "2025-06-20T18:13:18.275420Z",
     "shell.execute_reply": "2025-06-20T18:13:18.274756Z"
    },
    "papermill": {
     "duration": 0.011445,
     "end_time": "2025-06-20T18:13:18.276537",
     "exception": false,
     "start_time": "2025-06-20T18:13:18.265092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, class_weights, lr_scheduler=None):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "        \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "                    \n",
    "        logits = model(batch_x)\n",
    "                    \n",
    "        # Handle mixup targets\n",
    "        if batch_y.ndim == 2 and batch_y.shape[1] > 1:  # MixUp or one-hot\n",
    "            sample_weights = torch.sum(batch_y * class_weights.unsqueeze(0), dim=1)\n",
    "            log_probs = F.log_softmax(logits, dim=1)\n",
    "            loss_vec = -torch.sum(log_probs * batch_y, dim=1)  # (B,)\n",
    "            loss = (loss_vec * sample_weights).mean()\n",
    "            targets = batch_y.argmax(dim=1)\n",
    "        else:\n",
    "            targets = batch_y.long()\n",
    "            loss = label_smoothing_loss(logits, targets, smoothing=0.1)            \n",
    "        \n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ## Accmulate loss and accuracy\n",
    "        total_loss += loss.item() * batch_x.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == targets).sum().item()\n",
    "        total_samples += batch_x.size(0)\n",
    "        \n",
    "    if lr_scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    ## Normalize loss and accuracy\n",
    "    train_loss = total_loss/total_samples\n",
    "    train_acc  = total_correct/total_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abb49e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:18.285184Z",
     "iopub.status.busy": "2025-06-20T18:13:18.285015Z",
     "iopub.status.idle": "2025-06-20T18:13:18.290408Z",
     "shell.execute_reply": "2025-06-20T18:13:18.289910Z"
    },
    "papermill": {
     "duration": 0.010856,
     "end_time": "2025-06-20T18:13:18.291420",
     "exception": false,
     "start_time": "2025-06-20T18:13:18.280564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, lbl_encoder):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_correct, total_samples = 0, 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "            logits = model(batch_x)\n",
    "\n",
    "            # For both loss and metrics, assume batch_y is one-hot or integer labels\n",
    "            if batch_y.ndim == 2:\n",
    "                targets = batch_y.argmax(dim=1)\n",
    "            else:\n",
    "                targets = batch_y\n",
    "\n",
    "            # Computes loss and predictions\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            # Track batch metrics\n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += batch_x.size(0)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "    # Stack all predictions and targets\n",
    "    y_pred_all = torch.cat(all_preds).numpy()\n",
    "    y_val_all  = torch.cat(all_targets).numpy()\n",
    "\n",
    "    # Compute custom hierarchical F1\n",
    "    val_f1 = F1_score(y_val_all, y_pred_all, lbl_encoder, choice=\"weighted\")\n",
    "    val_loss = val_loss / total_samples\n",
    "    val_acc  = total_correct / total_samples\n",
    "\n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fecb0336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:18.299980Z",
     "iopub.status.busy": "2025-06-20T18:13:18.299762Z",
     "iopub.status.idle": "2025-06-20T18:13:18.305001Z",
     "shell.execute_reply": "2025-06-20T18:13:18.304538Z"
    },
    "papermill": {
     "duration": 0.010661,
     "end_time": "2025-06-20T18:13:18.306008",
     "exception": false,
     "start_time": "2025-06-20T18:13:18.295347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval(epochs, model, train_loader, val_loader, optimizer, class_weights, lbl_encoder, lr_scheduler=None):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    val_F1 = []\n",
    "    history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        ## Trains model\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, class_weights, lr_scheduler)\n",
    "\n",
    "        ## Evaluates model\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, lbl_encoder)\n",
    "\n",
    "        ## Append metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_F1.append(val_f1)\n",
    "\n",
    "        ## Checks early stopping\n",
    "        if early_stopper is not None:\n",
    "            early_stopper(model, val_f1)\n",
    "            if early_stopper.early_stop:\n",
    "                print(f\"\\nEarly stopping triggered at epoch {epoch+1}\\n\")\n",
    "                break\n",
    "                \n",
    "        ## Displays any result\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Accuracy: {train_acc:.3f}     Train Loss: {train_loss:.3f}\")\n",
    "        print(f\"Val Accuracy:   {val_acc:.3f}       Val F1:     {val_f1:.2f}     Val Loss:   {val_loss:.3f}\\n\")\n",
    "\n",
    "    ## Save results to history dictionary\n",
    "    history[\"train_losses\"] = train_losses\n",
    "    history[\"train_accuracies\"] = train_accuracies\n",
    "    history[\"val_losses\"] = val_losses\n",
    "    history[\"val_accuracies\"] = val_accuracies\n",
    "    history[\"val_F1\"] = val_F1\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2137953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:13:18.314475Z",
     "iopub.status.busy": "2025-06-20T18:13:18.314284Z",
     "iopub.status.idle": "2025-06-20T18:52:32.658848Z",
     "shell.execute_reply": "2025-06-20T18:52:32.657814Z"
    },
    "papermill": {
     "duration": 2354.365842,
     "end_time": "2025-06-20T18:52:32.675829",
     "exception": false,
     "start_time": "2025-06-20T18:13:18.309987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300]\n",
      "Train Accuracy: 0.140     Train Loss: 2.865\n",
      "Val Accuracy:   0.300       Val F1:     0.53     Val Loss:   2.132\n",
      "\n",
      "Epoch [2/300]\n",
      "Train Accuracy: 0.253     Train Loss: 2.376\n",
      "Val Accuracy:   0.418       Val F1:     0.64     Val Loss:   1.743\n",
      "\n",
      "Epoch [3/300]\n",
      "Train Accuracy: 0.325     Train Loss: 2.151\n",
      "Val Accuracy:   0.481       Val F1:     0.68     Val Loss:   1.556\n",
      "\n",
      "Epoch [4/300]\n",
      "Train Accuracy: 0.382     Train Loss: 2.004\n",
      "Val Accuracy:   0.505       Val F1:     0.69     Val Loss:   1.444\n",
      "\n",
      "Epoch [5/300]\n",
      "Train Accuracy: 0.424     Train Loss: 1.897\n",
      "Val Accuracy:   0.545       Val F1:     0.71     Val Loss:   1.318\n",
      "\n",
      "Epoch [6/300]\n",
      "Train Accuracy: 0.457     Train Loss: 1.806\n",
      "Val Accuracy:   0.548       Val F1:     0.72     Val Loss:   1.260\n",
      "\n",
      "Epoch [7/300]\n",
      "Train Accuracy: 0.477     Train Loss: 1.745\n",
      "Val Accuracy:   0.568       Val F1:     0.73     Val Loss:   1.213\n",
      "\n",
      "Epoch [8/300]\n",
      "Train Accuracy: 0.490     Train Loss: 1.700\n",
      "Val Accuracy:   0.573       Val F1:     0.74     Val Loss:   1.172\n",
      "\n",
      "Epoch [9/300]\n",
      "Train Accuracy: 0.523     Train Loss: 1.642\n",
      "Val Accuracy:   0.574       Val F1:     0.74     Val Loss:   1.149\n",
      "\n",
      "Epoch [10/300]\n",
      "Train Accuracy: 0.532     Train Loss: 1.627\n",
      "Val Accuracy:   0.601       Val F1:     0.75     Val Loss:   1.100\n",
      "\n",
      "Epoch [11/300]\n",
      "Train Accuracy: 0.547     Train Loss: 1.574\n",
      "Val Accuracy:   0.606       Val F1:     0.76     Val Loss:   1.083\n",
      "\n",
      "Epoch [12/300]\n",
      "Train Accuracy: 0.560     Train Loss: 1.553\n",
      "Val Accuracy:   0.611       Val F1:     0.76     Val Loss:   1.055\n",
      "\n",
      "Epoch [13/300]\n",
      "Train Accuracy: 0.566     Train Loss: 1.545\n",
      "Val Accuracy:   0.619       Val F1:     0.76     Val Loss:   1.035\n",
      "\n",
      "Epoch [14/300]\n",
      "Train Accuracy: 0.580     Train Loss: 1.503\n",
      "Val Accuracy:   0.632       Val F1:     0.77     Val Loss:   1.005\n",
      "\n",
      "Epoch [15/300]\n",
      "Train Accuracy: 0.592     Train Loss: 1.492\n",
      "Val Accuracy:   0.633       Val F1:     0.77     Val Loss:   0.975\n",
      "\n",
      "Epoch [16/300]\n",
      "Train Accuracy: 0.593     Train Loss: 1.484\n",
      "Val Accuracy:   0.639       Val F1:     0.78     Val Loss:   0.971\n",
      "\n",
      "Epoch [17/300]\n",
      "Train Accuracy: 0.608     Train Loss: 1.441\n",
      "Val Accuracy:   0.655       Val F1:     0.78     Val Loss:   0.958\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [18/300]\n",
      "Train Accuracy: 0.610     Train Loss: 1.439\n",
      "Val Accuracy:   0.642       Val F1:     0.78     Val Loss:   0.939\n",
      "\n",
      "Epoch [19/300]\n",
      "Train Accuracy: 0.622     Train Loss: 1.410\n",
      "Val Accuracy:   0.656       Val F1:     0.79     Val Loss:   0.924\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [20/300]\n",
      "Train Accuracy: 0.624     Train Loss: 1.411\n",
      "Val Accuracy:   0.644       Val F1:     0.78     Val Loss:   0.940\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [21/300]\n",
      "Train Accuracy: 0.631     Train Loss: 1.386\n",
      "Val Accuracy:   0.651       Val F1:     0.79     Val Loss:   0.942\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [22/300]\n",
      "Train Accuracy: 0.647     Train Loss: 1.369\n",
      "Val Accuracy:   0.658       Val F1:     0.78     Val Loss:   0.938\n",
      "\n",
      "Epoch [23/300]\n",
      "Train Accuracy: 0.649     Train Loss: 1.351\n",
      "Val Accuracy:   0.660       Val F1:     0.79     Val Loss:   0.901\n",
      "\n",
      "Epoch [24/300]\n",
      "Train Accuracy: 0.668     Train Loss: 1.345\n",
      "Val Accuracy:   0.682       Val F1:     0.80     Val Loss:   0.875\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [25/300]\n",
      "Train Accuracy: 0.663     Train Loss: 1.319\n",
      "Val Accuracy:   0.676       Val F1:     0.80     Val Loss:   0.892\n",
      "\n",
      "Epoch [26/300]\n",
      "Train Accuracy: 0.661     Train Loss: 1.325\n",
      "Val Accuracy:   0.682       Val F1:     0.81     Val Loss:   0.866\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [27/300]\n",
      "Train Accuracy: 0.675     Train Loss: 1.303\n",
      "Val Accuracy:   0.677       Val F1:     0.80     Val Loss:   0.877\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [28/300]\n",
      "Train Accuracy: 0.674     Train Loss: 1.292\n",
      "Val Accuracy:   0.681       Val F1:     0.80     Val Loss:   0.872\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [29/300]\n",
      "Train Accuracy: 0.688     Train Loss: 1.283\n",
      "Val Accuracy:   0.682       Val F1:     0.80     Val Loss:   0.856\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [30/300]\n",
      "Train Accuracy: 0.689     Train Loss: 1.249\n",
      "Val Accuracy:   0.671       Val F1:     0.80     Val Loss:   0.889\n",
      "\n",
      "Epoch [31/300]\n",
      "Train Accuracy: 0.701     Train Loss: 1.250\n",
      "Val Accuracy:   0.681       Val F1:     0.81     Val Loss:   0.878\n",
      "\n",
      "Epoch [32/300]\n",
      "Train Accuracy: 0.692     Train Loss: 1.263\n",
      "Val Accuracy:   0.700       Val F1:     0.81     Val Loss:   0.860\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [33/300]\n",
      "Train Accuracy: 0.693     Train Loss: 1.257\n",
      "Val Accuracy:   0.677       Val F1:     0.80     Val Loss:   0.928\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [34/300]\n",
      "Train Accuracy: 0.710     Train Loss: 1.219\n",
      "Val Accuracy:   0.668       Val F1:     0.80     Val Loss:   0.883\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [35/300]\n",
      "Train Accuracy: 0.702     Train Loss: 1.222\n",
      "Val Accuracy:   0.700       Val F1:     0.81     Val Loss:   0.854\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [36/300]\n",
      "Train Accuracy: 0.708     Train Loss: 1.202\n",
      "Val Accuracy:   0.688       Val F1:     0.81     Val Loss:   0.846\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [37/300]\n",
      "Train Accuracy: 0.720     Train Loss: 1.192\n",
      "Val Accuracy:   0.697       Val F1:     0.81     Val Loss:   0.833\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [38/300]\n",
      "Train Accuracy: 0.728     Train Loss: 1.187\n",
      "Val Accuracy:   0.691       Val F1:     0.81     Val Loss:   0.874\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [39/300]\n",
      "Train Accuracy: 0.717     Train Loss: 1.198\n",
      "Val Accuracy:   0.692       Val F1:     0.81     Val Loss:   0.864\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [40/300]\n",
      "Train Accuracy: 0.734     Train Loss: 1.168\n",
      "Val Accuracy:   0.685       Val F1:     0.81     Val Loss:   0.883\n",
      "\n",
      "Epoch [41/300]\n",
      "Train Accuracy: 0.738     Train Loss: 1.156\n",
      "Val Accuracy:   0.704       Val F1:     0.82     Val Loss:   0.866\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [42/300]\n",
      "Train Accuracy: 0.737     Train Loss: 1.147\n",
      "Val Accuracy:   0.703       Val F1:     0.82     Val Loss:   0.858\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [43/300]\n",
      "Train Accuracy: 0.739     Train Loss: 1.149\n",
      "Val Accuracy:   0.704       Val F1:     0.82     Val Loss:   0.855\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [44/300]\n",
      "Train Accuracy: 0.752     Train Loss: 1.128\n",
      "Val Accuracy:   0.702       Val F1:     0.82     Val Loss:   0.849\n",
      "\n",
      "Epoch [45/300]\n",
      "Train Accuracy: 0.752     Train Loss: 1.134\n",
      "Val Accuracy:   0.713       Val F1:     0.83     Val Loss:   0.817\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [46/300]\n",
      "Train Accuracy: 0.753     Train Loss: 1.123\n",
      "Val Accuracy:   0.705       Val F1:     0.82     Val Loss:   0.836\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [47/300]\n",
      "Train Accuracy: 0.761     Train Loss: 1.108\n",
      "Val Accuracy:   0.709       Val F1:     0.82     Val Loss:   0.840\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [48/300]\n",
      "Train Accuracy: 0.755     Train Loss: 1.129\n",
      "Val Accuracy:   0.712       Val F1:     0.83     Val Loss:   0.816\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [49/300]\n",
      "Train Accuracy: 0.764     Train Loss: 1.089\n",
      "Val Accuracy:   0.704       Val F1:     0.82     Val Loss:   0.826\n",
      "\n",
      "Epoch [50/300]\n",
      "Train Accuracy: 0.772     Train Loss: 1.086\n",
      "Val Accuracy:   0.722       Val F1:     0.83     Val Loss:   0.824\n",
      "\n",
      "Epoch [51/300]\n",
      "Train Accuracy: 0.770     Train Loss: 1.090\n",
      "Val Accuracy:   0.717       Val F1:     0.83     Val Loss:   0.822\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [52/300]\n",
      "Train Accuracy: 0.774     Train Loss: 1.084\n",
      "Val Accuracy:   0.705       Val F1:     0.82     Val Loss:   0.843\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [53/300]\n",
      "Train Accuracy: 0.771     Train Loss: 1.069\n",
      "Val Accuracy:   0.708       Val F1:     0.82     Val Loss:   0.814\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [54/300]\n",
      "Train Accuracy: 0.776     Train Loss: 1.056\n",
      "Val Accuracy:   0.716       Val F1:     0.82     Val Loss:   0.842\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [55/300]\n",
      "Train Accuracy: 0.771     Train Loss: 1.068\n",
      "Val Accuracy:   0.712       Val F1:     0.83     Val Loss:   0.833\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [56/300]\n",
      "Train Accuracy: 0.784     Train Loss: 1.052\n",
      "Val Accuracy:   0.708       Val F1:     0.82     Val Loss:   0.837\n",
      "\n",
      "Epoch [57/300]\n",
      "Train Accuracy: 0.791     Train Loss: 1.031\n",
      "Val Accuracy:   0.720       Val F1:     0.83     Val Loss:   0.817\n",
      "\n",
      "Epoch [58/300]\n",
      "Train Accuracy: 0.792     Train Loss: 1.048\n",
      "Val Accuracy:   0.728       Val F1:     0.83     Val Loss:   0.822\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [59/300]\n",
      "Train Accuracy: 0.799     Train Loss: 1.028\n",
      "Val Accuracy:   0.725       Val F1:     0.83     Val Loss:   0.818\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [60/300]\n",
      "Train Accuracy: 0.799     Train Loss: 1.020\n",
      "Val Accuracy:   0.709       Val F1:     0.83     Val Loss:   0.860\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [61/300]\n",
      "Train Accuracy: 0.792     Train Loss: 1.033\n",
      "Val Accuracy:   0.708       Val F1:     0.82     Val Loss:   0.878\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [62/300]\n",
      "Train Accuracy: 0.796     Train Loss: 1.029\n",
      "Val Accuracy:   0.719       Val F1:     0.83     Val Loss:   0.850\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [63/300]\n",
      "Train Accuracy: 0.799     Train Loss: 1.011\n",
      "Val Accuracy:   0.718       Val F1:     0.83     Val Loss:   0.846\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [64/300]\n",
      "Train Accuracy: 0.796     Train Loss: 1.017\n",
      "Val Accuracy:   0.714       Val F1:     0.82     Val Loss:   0.854\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [65/300]\n",
      "Train Accuracy: 0.800     Train Loss: 1.003\n",
      "Val Accuracy:   0.727       Val F1:     0.83     Val Loss:   0.831\n",
      "\n",
      "Epoch [66/300]\n",
      "Train Accuracy: 0.807     Train Loss: 0.984\n",
      "Val Accuracy:   0.731       Val F1:     0.83     Val Loss:   0.810\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [67/300]\n",
      "Train Accuracy: 0.813     Train Loss: 0.988\n",
      "Val Accuracy:   0.715       Val F1:     0.83     Val Loss:   0.857\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [68/300]\n",
      "Train Accuracy: 0.805     Train Loss: 0.997\n",
      "Val Accuracy:   0.721       Val F1:     0.83     Val Loss:   0.839\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [69/300]\n",
      "Train Accuracy: 0.810     Train Loss: 0.994\n",
      "Val Accuracy:   0.722       Val F1:     0.83     Val Loss:   0.851\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [70/300]\n",
      "Train Accuracy: 0.816     Train Loss: 0.979\n",
      "Val Accuracy:   0.728       Val F1:     0.83     Val Loss:   0.826\n",
      "\n",
      "Epoch [71/300]\n",
      "Train Accuracy: 0.821     Train Loss: 0.969\n",
      "Val Accuracy:   0.735       Val F1:     0.84     Val Loss:   0.843\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [72/300]\n",
      "Train Accuracy: 0.812     Train Loss: 0.987\n",
      "Val Accuracy:   0.699       Val F1:     0.82     Val Loss:   0.924\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [73/300]\n",
      "Train Accuracy: 0.824     Train Loss: 0.961\n",
      "Val Accuracy:   0.729       Val F1:     0.83     Val Loss:   0.862\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [74/300]\n",
      "Train Accuracy: 0.822     Train Loss: 0.962\n",
      "Val Accuracy:   0.714       Val F1:     0.82     Val Loss:   0.881\n",
      "\n",
      "Epoch [75/300]\n",
      "Train Accuracy: 0.816     Train Loss: 0.979\n",
      "Val Accuracy:   0.735       Val F1:     0.84     Val Loss:   0.844\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [76/300]\n",
      "Train Accuracy: 0.821     Train Loss: 0.966\n",
      "Val Accuracy:   0.720       Val F1:     0.83     Val Loss:   0.865\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [77/300]\n",
      "Train Accuracy: 0.823     Train Loss: 0.956\n",
      "Val Accuracy:   0.717       Val F1:     0.83     Val Loss:   0.885\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [78/300]\n",
      "Train Accuracy: 0.825     Train Loss: 0.961\n",
      "Val Accuracy:   0.727       Val F1:     0.83     Val Loss:   0.861\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [79/300]\n",
      "Train Accuracy: 0.829     Train Loss: 0.940\n",
      "Val Accuracy:   0.722       Val F1:     0.82     Val Loss:   0.853\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [80/300]\n",
      "Train Accuracy: 0.827     Train Loss: 0.953\n",
      "Val Accuracy:   0.730       Val F1:     0.83     Val Loss:   0.835\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [81/300]\n",
      "Train Accuracy: 0.827     Train Loss: 0.946\n",
      "Val Accuracy:   0.733       Val F1:     0.84     Val Loss:   0.829\n",
      "\n",
      "Epoch [82/300]\n",
      "Train Accuracy: 0.829     Train Loss: 0.945\n",
      "Val Accuracy:   0.738       Val F1:     0.84     Val Loss:   0.829\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [83/300]\n",
      "Train Accuracy: 0.839     Train Loss: 0.919\n",
      "Val Accuracy:   0.742       Val F1:     0.84     Val Loss:   0.847\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [84/300]\n",
      "Train Accuracy: 0.832     Train Loss: 0.950\n",
      "Val Accuracy:   0.734       Val F1:     0.84     Val Loss:   0.863\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [85/300]\n",
      "Train Accuracy: 0.833     Train Loss: 0.931\n",
      "Val Accuracy:   0.724       Val F1:     0.83     Val Loss:   0.854\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [86/300]\n",
      "Train Accuracy: 0.830     Train Loss: 0.930\n",
      "Val Accuracy:   0.722       Val F1:     0.83     Val Loss:   0.853\n",
      "\n",
      "Epoch [87/300]\n",
      "Train Accuracy: 0.847     Train Loss: 0.911\n",
      "Val Accuracy:   0.743       Val F1:     0.84     Val Loss:   0.846\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [88/300]\n",
      "Train Accuracy: 0.839     Train Loss: 0.917\n",
      "Val Accuracy:   0.742       Val F1:     0.84     Val Loss:   0.838\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [89/300]\n",
      "Train Accuracy: 0.841     Train Loss: 0.897\n",
      "Val Accuracy:   0.723       Val F1:     0.83     Val Loss:   0.874\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [90/300]\n",
      "Train Accuracy: 0.846     Train Loss: 0.907\n",
      "Val Accuracy:   0.736       Val F1:     0.84     Val Loss:   0.863\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [91/300]\n",
      "Train Accuracy: 0.842     Train Loss: 0.917\n",
      "Val Accuracy:   0.728       Val F1:     0.83     Val Loss:   0.861\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [92/300]\n",
      "Train Accuracy: 0.837     Train Loss: 0.927\n",
      "Val Accuracy:   0.723       Val F1:     0.83     Val Loss:   0.875\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [93/300]\n",
      "Train Accuracy: 0.844     Train Loss: 0.918\n",
      "Val Accuracy:   0.723       Val F1:     0.83     Val Loss:   0.856\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [94/300]\n",
      "Train Accuracy: 0.846     Train Loss: 0.904\n",
      "Val Accuracy:   0.738       Val F1:     0.84     Val Loss:   0.844\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [95/300]\n",
      "Train Accuracy: 0.855     Train Loss: 0.901\n",
      "Val Accuracy:   0.732       Val F1:     0.84     Val Loss:   0.873\n",
      "\n",
      "F1 EarlyStopping: 9/15\n",
      "\n",
      "Epoch [96/300]\n",
      "Train Accuracy: 0.850     Train Loss: 0.895\n",
      "Val Accuracy:   0.736       Val F1:     0.84     Val Loss:   0.834\n",
      "\n",
      "F1 EarlyStopping: 10/15\n",
      "\n",
      "Epoch [97/300]\n",
      "Train Accuracy: 0.846     Train Loss: 0.897\n",
      "Val Accuracy:   0.736       Val F1:     0.84     Val Loss:   0.829\n",
      "\n",
      "Epoch [98/300]\n",
      "Train Accuracy: 0.849     Train Loss: 0.899\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.861\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [99/300]\n",
      "Train Accuracy: 0.851     Train Loss: 0.901\n",
      "Val Accuracy:   0.742       Val F1:     0.84     Val Loss:   0.814\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [100/300]\n",
      "Train Accuracy: 0.853     Train Loss: 0.891\n",
      "Val Accuracy:   0.735       Val F1:     0.84     Val Loss:   0.861\n",
      "\n",
      "Epoch [101/300]\n",
      "Train Accuracy: 0.855     Train Loss: 0.882\n",
      "Val Accuracy:   0.751       Val F1:     0.85     Val Loss:   0.837\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [102/300]\n",
      "Train Accuracy: 0.859     Train Loss: 0.877\n",
      "Val Accuracy:   0.736       Val F1:     0.84     Val Loss:   0.828\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [103/300]\n",
      "Train Accuracy: 0.864     Train Loss: 0.864\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.836\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [104/300]\n",
      "Train Accuracy: 0.854     Train Loss: 0.871\n",
      "Val Accuracy:   0.746       Val F1:     0.84     Val Loss:   0.818\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [105/300]\n",
      "Train Accuracy: 0.859     Train Loss: 0.875\n",
      "Val Accuracy:   0.742       Val F1:     0.84     Val Loss:   0.832\n",
      "\n",
      "Epoch [106/300]\n",
      "Train Accuracy: 0.861     Train Loss: 0.863\n",
      "Val Accuracy:   0.755       Val F1:     0.85     Val Loss:   0.834\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [107/300]\n",
      "Train Accuracy: 0.860     Train Loss: 0.860\n",
      "Val Accuracy:   0.748       Val F1:     0.85     Val Loss:   0.857\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [108/300]\n",
      "Train Accuracy: 0.859     Train Loss: 0.871\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.804\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [109/300]\n",
      "Train Accuracy: 0.858     Train Loss: 0.866\n",
      "Val Accuracy:   0.744       Val F1:     0.85     Val Loss:   0.838\n",
      "\n",
      "Epoch [110/300]\n",
      "Train Accuracy: 0.867     Train Loss: 0.871\n",
      "Val Accuracy:   0.763       Val F1:     0.86     Val Loss:   0.844\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [111/300]\n",
      "Train Accuracy: 0.860     Train Loss: 0.858\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.868\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [112/300]\n",
      "Train Accuracy: 0.861     Train Loss: 0.862\n",
      "Val Accuracy:   0.737       Val F1:     0.84     Val Loss:   0.856\n",
      "\n",
      "Epoch [113/300]\n",
      "Train Accuracy: 0.863     Train Loss: 0.855\n",
      "Val Accuracy:   0.766       Val F1:     0.86     Val Loss:   0.820\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [114/300]\n",
      "Train Accuracy: 0.861     Train Loss: 0.858\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.831\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [115/300]\n",
      "Train Accuracy: 0.865     Train Loss: 0.850\n",
      "Val Accuracy:   0.727       Val F1:     0.83     Val Loss:   0.903\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [116/300]\n",
      "Train Accuracy: 0.860     Train Loss: 0.860\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.853\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [117/300]\n",
      "Train Accuracy: 0.864     Train Loss: 0.845\n",
      "Val Accuracy:   0.739       Val F1:     0.84     Val Loss:   0.856\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [118/300]\n",
      "Train Accuracy: 0.869     Train Loss: 0.845\n",
      "Val Accuracy:   0.761       Val F1:     0.86     Val Loss:   0.836\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [119/300]\n",
      "Train Accuracy: 0.862     Train Loss: 0.866\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.849\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [120/300]\n",
      "Train Accuracy: 0.865     Train Loss: 0.844\n",
      "Val Accuracy:   0.744       Val F1:     0.85     Val Loss:   0.852\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [121/300]\n",
      "Train Accuracy: 0.864     Train Loss: 0.839\n",
      "Val Accuracy:   0.744       Val F1:     0.84     Val Loss:   0.870\n",
      "\n",
      "F1 EarlyStopping: 9/15\n",
      "\n",
      "Epoch [122/300]\n",
      "Train Accuracy: 0.874     Train Loss: 0.833\n",
      "Val Accuracy:   0.746       Val F1:     0.85     Val Loss:   0.893\n",
      "\n",
      "F1 EarlyStopping: 10/15\n",
      "\n",
      "Epoch [123/300]\n",
      "Train Accuracy: 0.868     Train Loss: 0.835\n",
      "Val Accuracy:   0.742       Val F1:     0.84     Val Loss:   0.881\n",
      "\n",
      "F1 EarlyStopping: 11/15\n",
      "\n",
      "Epoch [124/300]\n",
      "Train Accuracy: 0.873     Train Loss: 0.832\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.886\n",
      "\n",
      "F1 EarlyStopping: 12/15\n",
      "\n",
      "Epoch [125/300]\n",
      "Train Accuracy: 0.871     Train Loss: 0.833\n",
      "Val Accuracy:   0.747       Val F1:     0.85     Val Loss:   0.889\n",
      "\n",
      "Epoch [126/300]\n",
      "Train Accuracy: 0.868     Train Loss: 0.833\n",
      "Val Accuracy:   0.767       Val F1:     0.86     Val Loss:   0.861\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [127/300]\n",
      "Train Accuracy: 0.865     Train Loss: 0.838\n",
      "Val Accuracy:   0.744       Val F1:     0.84     Val Loss:   0.864\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [128/300]\n",
      "Train Accuracy: 0.871     Train Loss: 0.839\n",
      "Val Accuracy:   0.735       Val F1:     0.84     Val Loss:   0.906\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [129/300]\n",
      "Train Accuracy: 0.865     Train Loss: 0.834\n",
      "Val Accuracy:   0.751       Val F1:     0.85     Val Loss:   0.858\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [130/300]\n",
      "Train Accuracy: 0.875     Train Loss: 0.824\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.858\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [131/300]\n",
      "Train Accuracy: 0.874     Train Loss: 0.825\n",
      "Val Accuracy:   0.745       Val F1:     0.85     Val Loss:   0.919\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [132/300]\n",
      "Train Accuracy: 0.873     Train Loss: 0.826\n",
      "Val Accuracy:   0.746       Val F1:     0.85     Val Loss:   0.870\n",
      "\n",
      "Epoch [133/300]\n",
      "Train Accuracy: 0.874     Train Loss: 0.817\n",
      "Val Accuracy:   0.758       Val F1:     0.86     Val Loss:   0.853\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [134/300]\n",
      "Train Accuracy: 0.873     Train Loss: 0.822\n",
      "Val Accuracy:   0.754       Val F1:     0.85     Val Loss:   0.862\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [135/300]\n",
      "Train Accuracy: 0.872     Train Loss: 0.819\n",
      "Val Accuracy:   0.744       Val F1:     0.84     Val Loss:   0.883\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [136/300]\n",
      "Train Accuracy: 0.880     Train Loss: 0.817\n",
      "Val Accuracy:   0.734       Val F1:     0.84     Val Loss:   0.923\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [137/300]\n",
      "Train Accuracy: 0.877     Train Loss: 0.817\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.898\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [138/300]\n",
      "Train Accuracy: 0.868     Train Loss: 0.810\n",
      "Val Accuracy:   0.741       Val F1:     0.84     Val Loss:   0.904\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [139/300]\n",
      "Train Accuracy: 0.876     Train Loss: 0.820\n",
      "Val Accuracy:   0.754       Val F1:     0.85     Val Loss:   0.861\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [140/300]\n",
      "Train Accuracy: 0.877     Train Loss: 0.800\n",
      "Val Accuracy:   0.745       Val F1:     0.84     Val Loss:   0.887\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [141/300]\n",
      "Train Accuracy: 0.881     Train Loss: 0.813\n",
      "Val Accuracy:   0.752       Val F1:     0.85     Val Loss:   0.838\n",
      "\n",
      "F1 EarlyStopping: 9/15\n",
      "\n",
      "Epoch [142/300]\n",
      "Train Accuracy: 0.873     Train Loss: 0.810\n",
      "Val Accuracy:   0.753       Val F1:     0.85     Val Loss:   0.845\n",
      "\n",
      "F1 EarlyStopping: 10/15\n",
      "\n",
      "Epoch [143/300]\n",
      "Train Accuracy: 0.877     Train Loss: 0.803\n",
      "Val Accuracy:   0.739       Val F1:     0.84     Val Loss:   0.874\n",
      "\n",
      "F1 EarlyStopping: 11/15\n",
      "\n",
      "Epoch [144/300]\n",
      "Train Accuracy: 0.880     Train Loss: 0.806\n",
      "Val Accuracy:   0.755       Val F1:     0.85     Val Loss:   0.845\n",
      "\n",
      "F1 EarlyStopping: 12/15\n",
      "\n",
      "Epoch [145/300]\n",
      "Train Accuracy: 0.883     Train Loss: 0.789\n",
      "Val Accuracy:   0.750       Val F1:     0.85     Val Loss:   0.856\n",
      "\n",
      "F1 EarlyStopping: 13/15\n",
      "\n",
      "Epoch [146/300]\n",
      "Train Accuracy: 0.883     Train Loss: 0.806\n",
      "Val Accuracy:   0.757       Val F1:     0.85     Val Loss:   0.877\n",
      "\n",
      "F1 EarlyStopping: 14/15\n",
      "\n",
      "Epoch [147/300]\n",
      "Train Accuracy: 0.880     Train Loss: 0.810\n",
      "Val Accuracy:   0.754       Val F1:     0.85     Val Loss:   0.893\n",
      "\n",
      "F1 EarlyStopping: 15/15\n",
      "\n",
      "\n",
      "Early stopping triggered at epoch 148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopper = F1EarlyStopping(PATIENCE, verbose=True)\n",
    "\n",
    "train_history = train_eval(\n",
    "    EPOCHS, \n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    optimizer, \n",
    "    class_weights, \n",
    "    label_encoder, \n",
    "    scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45d28443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:52:32.696644Z",
     "iopub.status.busy": "2025-06-20T18:52:32.696385Z",
     "iopub.status.idle": "2025-06-20T18:52:32.706022Z",
     "shell.execute_reply": "2025-06-20T18:52:32.705402Z"
    },
    "papermill": {
     "duration": 0.021423,
     "end_time": "2025-06-20T18:52:32.707072",
     "exception": false,
     "start_time": "2025-06-20T18:52:32.685649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_history.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_history, \"train_history.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 245998721,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 246234309,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2377.187213,
   "end_time": "2025-06-20T18:52:36.261845",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T18:12:59.074632",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
