{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20353ada",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-09T16:48:26.184585Z",
     "iopub.status.busy": "2025-06-09T16:48:26.184196Z",
     "iopub.status.idle": "2025-06-09T16:48:29.983398Z",
     "shell.execute_reply": "2025-06-09T16:48:29.982120Z"
    },
    "papermill": {
     "duration": 3.806071,
     "end_time": "2025-06-09T16:48:29.985319",
     "exception": false,
     "start_time": "2025-06-09T16:48:26.179248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbdff69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:48:29.993155Z",
     "iopub.status.busy": "2025-06-09T16:48:29.992631Z",
     "iopub.status.idle": "2025-06-09T16:49:07.277343Z",
     "shell.execute_reply": "2025-06-09T16:49:07.276329Z"
    },
    "papermill": {
     "duration": 37.290639,
     "end_time": "2025-06-09T16:49:07.279389",
     "exception": false,
     "start_time": "2025-06-09T16:48:29.988750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\")\n",
    "test  = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\")\n",
    "test_demo  = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\")\n",
    "train_demo = pd.read_csv(\"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790c07d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:49:07.287052Z",
     "iopub.status.busy": "2025-06-09T16:49:07.286681Z",
     "iopub.status.idle": "2025-06-09T16:49:07.404026Z",
     "shell.execute_reply": "2025-06-09T16:49:07.403103Z"
    },
    "papermill": {
     "duration": 0.12277,
     "end_time": "2025-06-09T16:49:07.405619",
     "exception": false,
     "start_time": "2025-06-09T16:49:07.282849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded gestures: 18 classes\n",
      "Classes: ['Above ear - pull hair' 'Cheek - pinch skin' 'Drink from bottle/cup'\n",
      " 'Eyebrow - pull hair' 'Eyelash - pull hair'\n",
      " 'Feel around in tray and pull out an object' 'Forehead - pull hairline'\n",
      " 'Forehead - scratch' 'Glasses on/off' 'Neck - pinch skin'\n",
      " 'Neck - scratch' 'Pinch knee/leg skin' 'Pull air toward your face'\n",
      " 'Scratch knee/leg skin' 'Text on phone' 'Wave hello' 'Write name in air'\n",
      " 'Write name on leg']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train['encoded_gesture'] = le.fit_transform(train['gesture'])\n",
    "\n",
    "print(f\"\\nEncoded gestures: {len(le.classes_)} classes\")\n",
    "print(\"Classes:\", le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42652a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:49:07.412941Z",
     "iopub.status.busy": "2025-06-09T16:49:07.412616Z",
     "iopub.status.idle": "2025-06-09T16:49:07.420037Z",
     "shell.execute_reply": "2025-06-09T16:49:07.419292Z"
    },
    "papermill": {
     "duration": 0.012848,
     "end_time": "2025-06-09T16:49:07.421666",
     "exception": false,
     "start_time": "2025-06-09T16:49:07.408818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ca5628",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T16:49:07.430365Z",
     "iopub.status.busy": "2025-06-09T16:49:07.430065Z",
     "iopub.status.idle": "2025-06-09T16:49:07.440021Z",
     "shell.execute_reply": "2025-06-09T16:49:07.439163Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015831,
     "end_time": "2025-06-09T16:49:07.441366",
     "exception": false,
     "start_time": "2025-06-09T16:49:07.425535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing make_sequence_summary_features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile make_sequence_summary_features.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_sequence_summary_features(df, demographics_df=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive features from sensor sequences\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Group by sequence_id to create sequence-level features\n",
    "    for seq_id, group in df.groupby('sequence_id'):\n",
    "        seq_features = {'sequence_id': seq_id}\n",
    "        columns = set(group.columns)\n",
    "        \n",
    "        # Basic sequence info\n",
    "        seq_features['sequence_length'] = len(group)\n",
    "        seq_features['subject'] = group['subject'].iloc[0]\n",
    "        \n",
    "        # Add demographics if available\n",
    "        if (demographics_df is not None) and (not demographics_df.empty):\n",
    "            subject_demo = demographics_df[ demographics_df['subject'] == seq_features['subject'] ]\n",
    "            if not subject_demo.empty:\n",
    "                seq_features['adult_child'] = subject_demo['adult_child'].iloc[0]\n",
    "                seq_features['age'] = subject_demo['age'].iloc[0]\n",
    "                seq_features['sex'] = subject_demo['sex'].iloc[0]\n",
    "                seq_features['handedness'] = subject_demo['handedness'].iloc[0]\n",
    "                seq_features['height_cm']  = subject_demo['height_cm'].iloc[0]\n",
    "                seq_features['shoulder_to_wrist_cm'] = subject_demo['shoulder_to_wrist_cm'].iloc[0]\n",
    "                seq_features['elbow_to_wrist_cm']    = subject_demo['elbow_to_wrist_cm'].iloc[0]\n",
    "            else:\n",
    "                # Set default values if demographics not found\n",
    "                seq_features['adult_child'] = -1\n",
    "                seq_features['age'] = -1\n",
    "                seq_features['sex'] = -1\n",
    "                seq_features['handedness'] = -1\n",
    "                seq_features['height_cm'] = -1\n",
    "                seq_features['shoulder_to_wrist_cm'] = -1\n",
    "                seq_features['elbow_to_wrist_cm'] = -1\n",
    "        else:\n",
    "            # Set default values if demographics not available\n",
    "            seq_features['adult_child'] = -1\n",
    "            seq_features['age'] = -1\n",
    "            seq_features['sex'] = -1\n",
    "            seq_features['handedness'] = -1\n",
    "            seq_features['height_cm'] = -1\n",
    "            seq_features['shoulder_to_wrist_cm'] = -1\n",
    "            seq_features['elbow_to_wrist_cm'] = -1\n",
    "        \n",
    "        # Behavior phase encoding (if available)\n",
    "        if 'behavior' in columns:\n",
    "            behavior_counts = group['behavior'].value_counts()\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = behavior_counts.get(behavior, 0)\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = behavior_counts.get(behavior, 0) / len(group)\n",
    "        else:\n",
    "            # Set default values if behavior column is not available\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = 0\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = 0\n",
    "        \n",
    "        # Statistical features for each sensor type\n",
    "        sensor_groups = {\n",
    "            'acc': ['acc_x', 'acc_y', 'acc_z'],\n",
    "            'rot': ['rot_w', 'rot_x', 'rot_y', 'rot_z'],\n",
    "            'thm': [\"thm_1\", \"thm_2\", \"thm_3\", \"thm_4\", \"thm_5\"],\n",
    "            'tof': [f\"tof_{i}_v{j}\" for i in range(1,6) for j in range(0,64)]\n",
    "        }\n",
    "        \n",
    "        for sensor_type, cols in sensor_groups.items():\n",
    "            available_cols = [col for col in cols if col in columns]\n",
    "            if available_cols:\n",
    "                sensor_data = group[available_cols].values        \n",
    "                # Basic statistics\n",
    "                seq_features[f'{sensor_type}_mean'] = np.mean(sensor_data)\n",
    "                seq_features[f'{sensor_type}_std']  = np.std(sensor_data)\n",
    "                seq_features[f'{sensor_type}_min']  = np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_max']  = np.max(sensor_data)\n",
    "                seq_features[f'{sensor_type}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_median'] = np.median(sensor_data)\n",
    "                \n",
    "                # Percentiles\n",
    "                seq_features[f'{sensor_type}_q25'] = np.percentile(sensor_data, 25)\n",
    "                seq_features[f'{sensor_type}_q75'] = np.percentile(sensor_data, 75)\n",
    "                seq_features[f'{sensor_type}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "                # Signal characteristics\n",
    "                seq_features[f'{sensor_type}_energy'] = np.sum(sensor_data**2)\n",
    "                seq_features[f'{sensor_type}_rms'] = np.sqrt(np.mean(sensor_data**2))\n",
    "\n",
    "                if sensor_type != \"tof\":\n",
    "                    for col in available_cols:\n",
    "                        sensor_data = group[col].values\n",
    "                        seq_features[f'{col}_mean'] = np.mean(sensor_data)\n",
    "                        seq_features[f'{col}_std']  = np.std(sensor_data)\n",
    "                        seq_features[f'{col}_min']  = np.min(sensor_data)\n",
    "                        seq_features[f'{col}_max']  = np.max(sensor_data)\n",
    "                        seq_features[f'{col}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                        seq_features[f'{col}_median'] = np.median(sensor_data)\n",
    "                    \n",
    "                        # Percentiles\n",
    "                        seq_features[f'{col}_q25'] = np.percentile(sensor_data, 25)\n",
    "                        seq_features[f'{col}_q75'] = np.percentile(sensor_data, 75)\n",
    "                        seq_features[f'{col}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "        # Specific features for IMU data (acceleration and rotation)\n",
    "        if all(col in columns for col in ['acc_x', 'acc_y', 'acc_z']):\n",
    "            acc_data = group[['acc_x', 'acc_y', 'acc_z']].values\n",
    "            # Acceleration features\n",
    "            acc_magnitude = np.sqrt(np.sum(acc_data**2, axis=1))\n",
    "            jerk = np.nan_to_num(np.diff(acc_magnitude), nan=-666)\n",
    "            seq_features['jerk_mean'] = np.mean(jerk)\n",
    "            seq_features['jerk_std'] = np.std(jerk)\n",
    "            seq_features['acc_magnitude_mean'] = np.mean(acc_magnitude)\n",
    "            seq_features['acc_magnitude_std'] = np.std(acc_magnitude)\n",
    "            seq_features['acc_magnitude_max'] = np.max(acc_magnitude)\n",
    "            seq_features['acc_height_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['height_cm'], 1)\n",
    "            seq_features['acc_shoulder_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['shoulder_to_wrist_cm'], 1)\n",
    "            seq_features['acc_elbow_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['elbow_to_wrist_cm'], 1)\n",
    "            seq_features['acc_xy_corr'] = np.corrcoef(group['acc_x'], group['acc_y'])[0, 1]\n",
    "            seq_features['acc_yz_corr'] = np.corrcoef(group['acc_y'], group['acc_z'])[0, 1]\n",
    "            seq_features['acc_xz_corr'] = np.corrcoef(group['acc_x'], group['acc_z'])[0, 1]\n",
    "            seq_features[\"acc_x_cumsum\"] = np.sum(group[\"acc_x\"])\n",
    "            seq_features[\"acc_y_cumsum\"] = np.sum(group[\"acc_y\"])\n",
    "            seq_features[\"acc_z_cumsum\"] = np.sum(group[\"acc_z\"])\n",
    "            \n",
    "        # Rotational features\n",
    "        rot_angle = 2*np.arccos(np.clip(group[\"rot_w\"].values, -1.0, 1.0))\n",
    "        angular_velocity = np.nan_to_num(np.diff(rot_angle), nan=-666)\n",
    "        angular_acceleration = np.nan_to_num(np.diff(angular_velocity), nan=-666)\n",
    "        seq_features['rot_wx_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_x'])[0, 1], nan=-666)\n",
    "        seq_features['rot_wy_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_y'])[0, 1], nan=-666)\n",
    "        seq_features['rot_wz_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['rot_xy_corr'] = np.nan_to_num(np.corrcoef(group['rot_x'], group['rot_y'])[0, 1], nan=-666)\n",
    "        seq_features['rot_xz_corr'] = np.nan_to_num(np.corrcoef(group['rot_x'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['rot_yz_corr'] = np.nan_to_num(np.corrcoef(group['rot_y'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['angular_velocity_mean'] = np.mean(angular_velocity)\n",
    "        seq_features['angular_velocity_std'] = np.std(angular_velocity)\n",
    "        seq_features['angular_accel_mean'] = np.mean(angular_acceleration)\n",
    "        seq_features['angular_accel_std'] = np.std(angular_acceleration)\n",
    "        seq_features[\"rot_angle_cumsum\"] = np.sum(rot_angle)\n",
    "        seq_features[\"rot_angle_mean\"] = np.mean(rot_angle)\n",
    "        seq_features[\"rot_angle_median\"] = np.median(rot_angle)\n",
    "        seq_features[\"rot_angle_std\"]  = np.std(rot_angle)\n",
    "        seq_features[\"rot_angle_min\"]  = np.min(rot_angle)    \n",
    "        seq_features[\"rot_angle_max\"]  = np.max(rot_angle)\n",
    "        seq_features[\"rot_angle_range\"]  = np.max(rot_angle) - np.min(rot_angle)\n",
    "        seq_features[\"rot_angle_q25\"] = np.percentile(rot_angle, 25)\n",
    "        seq_features[\"rot_angle_q75\"] = np.percentile(rot_angle, 75)\n",
    "        seq_features[\"rot_angle_iqr\"] = np.percentile(rot_angle, 75) - np.percentile(rot_angle, 25)                \n",
    "        seq_features['rot_angle_energy'] = np.sum(rot_angle**2)\n",
    "        seq_features['rot_angle_rms'] = np.sqrt(np.mean(rot_angle**2))\n",
    "        \n",
    "        # Add target if available\n",
    "        if 'encoded_gesture' in columns:\n",
    "            seq_features['target'] = group['encoded_gesture'].iloc[0]\n",
    "            seq_features['gesture'] = group['gesture'].iloc[0]\n",
    "        \n",
    "        features.append(seq_features)\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa68e143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:49:07.449406Z",
     "iopub.status.busy": "2025-06-09T16:49:07.448924Z",
     "iopub.status.idle": "2025-06-09T16:49:07.475220Z",
     "shell.execute_reply": "2025-06-09T16:49:07.474281Z"
    },
    "papermill": {
     "duration": 0.032309,
     "end_time": "2025-06-09T16:49:07.476947",
     "exception": false,
     "start_time": "2025-06-09T16:49:07.444638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_sequence_summary_features(df, demographics_df=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive features from sensor sequences\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Group by sequence_id to create sequence-level features\n",
    "    for seq_id, group in df.groupby('sequence_id'):\n",
    "        seq_features = {'sequence_id': seq_id}\n",
    "        columns = set(group.columns)\n",
    "        \n",
    "        # Basic sequence info\n",
    "        seq_features['sequence_length'] = len(group)\n",
    "        seq_features['subject'] = group['subject'].iloc[0]\n",
    "        \n",
    "        # Add demographics if available\n",
    "        if (demographics_df is not None) and (not demographics_df.empty):\n",
    "            subject_demo = demographics_df[ demographics_df['subject'] == seq_features['subject'] ]\n",
    "            if not subject_demo.empty:\n",
    "                seq_features['adult_child'] = subject_demo['adult_child'].iloc[0]\n",
    "                seq_features['age'] = subject_demo['age'].iloc[0]\n",
    "                seq_features['sex'] = subject_demo['sex'].iloc[0]\n",
    "                seq_features['handedness'] = subject_demo['handedness'].iloc[0]\n",
    "                seq_features['height_cm']  = subject_demo['height_cm'].iloc[0]\n",
    "                seq_features['shoulder_to_wrist_cm'] = subject_demo['shoulder_to_wrist_cm'].iloc[0]\n",
    "                seq_features['elbow_to_wrist_cm']    = subject_demo['elbow_to_wrist_cm'].iloc[0]\n",
    "            else:\n",
    "                # Set default values if demographics not found\n",
    "                seq_features['adult_child'] = -1\n",
    "                seq_features['age'] = -1\n",
    "                seq_features['sex'] = -1\n",
    "                seq_features['handedness'] = -1\n",
    "                seq_features['height_cm'] = -1\n",
    "                seq_features['shoulder_to_wrist_cm'] = -1\n",
    "                seq_features['elbow_to_wrist_cm'] = -1\n",
    "        else:\n",
    "            # Set default values if demographics not available\n",
    "            seq_features['adult_child'] = -1\n",
    "            seq_features['age'] = -1\n",
    "            seq_features['sex'] = -1\n",
    "            seq_features['handedness'] = -1\n",
    "            seq_features['height_cm'] = -1\n",
    "            seq_features['shoulder_to_wrist_cm'] = -1\n",
    "            seq_features['elbow_to_wrist_cm'] = -1\n",
    "        \n",
    "        # Behavior phase encoding (if available)\n",
    "        if 'behavior' in columns:\n",
    "            behavior_counts = group['behavior'].value_counts()\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = behavior_counts.get(behavior, 0)\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = behavior_counts.get(behavior, 0) / len(group)\n",
    "        else:\n",
    "            # Set default values if behavior column is not available\n",
    "            for behavior in ['Transition', 'Pause', 'Gesture']:\n",
    "                seq_features[f'{behavior.lower()}_count'] = 0\n",
    "                seq_features[f'{behavior.lower()}_ratio'] = 0\n",
    "        \n",
    "        # Statistical features for each sensor type\n",
    "        sensor_groups = {\n",
    "            'acc': ['acc_x', 'acc_y', 'acc_z'],\n",
    "            'rot': ['rot_w', 'rot_x', 'rot_y', 'rot_z'],\n",
    "            'thm': [\"thm_1\", \"thm_2\", \"thm_3\", \"thm_4\", \"thm_5\"],\n",
    "            'tof': [f\"tof_{i}_v{j}\" for i in range(1,6) for j in range(0,64)]\n",
    "        }\n",
    "        \n",
    "        for sensor_type, cols in sensor_groups.items():\n",
    "            available_cols = [col for col in cols if col in columns]\n",
    "            if available_cols:\n",
    "                sensor_data = group[available_cols].values        \n",
    "                # Basic statistics\n",
    "                seq_features[f'{sensor_type}_mean'] = np.mean(sensor_data)\n",
    "                seq_features[f'{sensor_type}_std']  = np.std(sensor_data)\n",
    "                seq_features[f'{sensor_type}_min']  = np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_max']  = np.max(sensor_data)\n",
    "                seq_features[f'{sensor_type}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                seq_features[f'{sensor_type}_median'] = np.median(sensor_data)\n",
    "                \n",
    "                # Percentiles\n",
    "                seq_features[f'{sensor_type}_q25'] = np.percentile(sensor_data, 25)\n",
    "                seq_features[f'{sensor_type}_q75'] = np.percentile(sensor_data, 75)\n",
    "                seq_features[f'{sensor_type}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "                # Signal characteristics\n",
    "                seq_features[f'{sensor_type}_energy'] = np.sum(sensor_data**2)\n",
    "                seq_features[f'{sensor_type}_rms'] = np.sqrt(np.mean(sensor_data**2))\n",
    "\n",
    "                if sensor_type != \"tof\":\n",
    "                    for col in available_cols:\n",
    "                        sensor_data = group[col].values\n",
    "                        seq_features[f'{col}_mean'] = np.mean(sensor_data)\n",
    "                        seq_features[f'{col}_std']  = np.std(sensor_data)\n",
    "                        seq_features[f'{col}_min']  = np.min(sensor_data)\n",
    "                        seq_features[f'{col}_max']  = np.max(sensor_data)\n",
    "                        seq_features[f'{col}_range']  = np.max(sensor_data) - np.min(sensor_data)\n",
    "                        seq_features[f'{col}_median'] = np.median(sensor_data)\n",
    "                    \n",
    "                        # Percentiles\n",
    "                        seq_features[f'{col}_q25'] = np.percentile(sensor_data, 25)\n",
    "                        seq_features[f'{col}_q75'] = np.percentile(sensor_data, 75)\n",
    "                        seq_features[f'{col}_iqr'] = np.percentile(sensor_data, 75) - np.percentile(sensor_data, 25)                \n",
    "                \n",
    "        # Specific features for IMU data (acceleration and rotation)\n",
    "        if all(col in columns for col in ['acc_x', 'acc_y', 'acc_z']):\n",
    "            acc_data = group[['acc_x', 'acc_y', 'acc_z']].values\n",
    "            # Acceleration features\n",
    "            acc_magnitude = np.sqrt(np.sum(acc_data**2, axis=1))\n",
    "            jerk = np.nan_to_num(np.diff(acc_magnitude), nan=-666)\n",
    "            seq_features['jerk_mean'] = np.mean(jerk)\n",
    "            seq_features['jerk_std'] = np.std(jerk)\n",
    "            seq_features['acc_magnitude_mean'] = np.mean(acc_magnitude)\n",
    "            seq_features['acc_magnitude_std'] = np.std(acc_magnitude)\n",
    "            seq_features['acc_magnitude_max'] = np.max(acc_magnitude)\n",
    "            seq_features['acc_height_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['height_cm'], 1)\n",
    "            seq_features['acc_shoulder_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['shoulder_to_wrist_cm'], 1)\n",
    "            seq_features['acc_elbow_norm'] = seq_features['acc_magnitude_mean'] / max(seq_features['elbow_to_wrist_cm'], 1)\n",
    "            seq_features['acc_xy_corr'] = np.corrcoef(group['acc_x'], group['acc_y'])[0, 1]\n",
    "            seq_features['acc_yz_corr'] = np.corrcoef(group['acc_y'], group['acc_z'])[0, 1]\n",
    "            seq_features['acc_xz_corr'] = np.corrcoef(group['acc_x'], group['acc_z'])[0, 1]\n",
    "            seq_features[\"acc_x_cumsum\"] = np.sum(group[\"acc_x\"])\n",
    "            seq_features[\"acc_y_cumsum\"] = np.sum(group[\"acc_y\"])\n",
    "            seq_features[\"acc_z_cumsum\"] = np.sum(group[\"acc_z\"])\n",
    "            \n",
    "        # Rotational features\n",
    "        rot_angle = 2*np.arccos(np.clip(group[\"rot_w\"].values, -1.0, 1.0))\n",
    "        angular_velocity = np.nan_to_num(np.diff(rot_angle), nan=-666)\n",
    "        angular_acceleration = np.nan_to_num(np.diff(angular_velocity), nan=-666)\n",
    "        seq_features['rot_wx_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_x'])[0, 1], nan=-666)\n",
    "        seq_features['rot_wy_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_y'])[0, 1], nan=-666)\n",
    "        seq_features['rot_wz_corr'] = np.nan_to_num(np.corrcoef(group['rot_w'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['rot_xy_corr'] = np.nan_to_num(np.corrcoef(group['rot_x'], group['rot_y'])[0, 1], nan=-666)\n",
    "        seq_features['rot_xz_corr'] = np.nan_to_num(np.corrcoef(group['rot_x'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['rot_yz_corr'] = np.nan_to_num(np.corrcoef(group['rot_y'], group['rot_z'])[0, 1], nan=-666)\n",
    "        seq_features['angular_velocity_mean'] = np.mean(angular_velocity)\n",
    "        seq_features['angular_velocity_std'] = np.std(angular_velocity)\n",
    "        seq_features['angular_accel_mean'] = np.mean(angular_acceleration)\n",
    "        seq_features['angular_accel_std'] = np.std(angular_acceleration)\n",
    "        seq_features[\"rot_angle_cumsum\"] = np.sum(rot_angle)\n",
    "        seq_features[\"rot_angle_mean\"] = np.mean(rot_angle)\n",
    "        seq_features[\"rot_angle_median\"] = np.median(rot_angle)\n",
    "        seq_features[\"rot_angle_std\"]  = np.std(rot_angle)\n",
    "        seq_features[\"rot_angle_min\"]  = np.min(rot_angle)    \n",
    "        seq_features[\"rot_angle_max\"]  = np.max(rot_angle)\n",
    "        seq_features[\"rot_angle_range\"]  = np.max(rot_angle) - np.min(rot_angle)\n",
    "        seq_features[\"rot_angle_q25\"] = np.percentile(rot_angle, 25)\n",
    "        seq_features[\"rot_angle_q75\"] = np.percentile(rot_angle, 75)\n",
    "        seq_features[\"rot_angle_iqr\"] = np.percentile(rot_angle, 75) - np.percentile(rot_angle, 25)                \n",
    "        seq_features['rot_angle_energy'] = np.sum(rot_angle**2)\n",
    "        seq_features['rot_angle_rms'] = np.sqrt(np.mean(rot_angle**2))\n",
    "        \n",
    "        # Add target if available\n",
    "        if 'encoded_gesture' in columns:\n",
    "            seq_features['target'] = group['encoded_gesture'].iloc[0]\n",
    "            seq_features['gesture'] = group['gesture'].iloc[0]\n",
    "        \n",
    "        features.append(seq_features)\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2c0dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:49:07.484319Z",
     "iopub.status.busy": "2025-06-09T16:49:07.483996Z",
     "iopub.status.idle": "2025-06-09T16:51:40.275350Z",
     "shell.execute_reply": "2025-06-09T16:51:40.274166Z"
    },
    "papermill": {
     "duration": 152.798325,
     "end_time": "2025-06-09T16:51:40.278502",
     "exception": false,
     "start_time": "2025-06-09T16:49:07.480177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sequence-level features...\n",
      "Training features shape: (8151, 206)\n"
     ]
    }
   ],
   "source": [
    "# Create features\n",
    "print(\"\\nCreating sequence-level features...\")\n",
    "train = train.fillna(-1)\n",
    "train_features = make_sequence_summary_features(train, train_demo)\n",
    "print(f\"Training features shape: {train_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cec822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:51:40.288499Z",
     "iopub.status.busy": "2025-06-09T16:51:40.288139Z",
     "iopub.status.idle": "2025-06-09T16:51:40.297673Z",
     "shell.execute_reply": "2025-06-09T16:51:40.296214Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016893,
     "end_time": "2025-06-09T16:51:40.299771",
     "exception": false,
     "start_time": "2025-06-09T16:51:40.282878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hierachical_macro_f1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hierachical_macro_f1.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        f1_binary = f1_score(\n",
    "            y_true_bin,\n",
    "            y_pred_bin,\n",
    "            pos_label=True,\n",
    "            zero_division=0,\n",
    "            average='binary'\n",
    "        )\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        # Compute macro F1 over all gesture classes\n",
    "        f1_macro = f1_score(\n",
    "            y_true_mc,\n",
    "            y_pred_mc,\n",
    "            average='macro',\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        return 0.5 * f1_binary + 0.5 * f1_macro\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute hierarchical macro F1 for the CMI 2025 challenge.\n",
    "\n",
    "    Expected input:\n",
    "      - solution and submission as pandas.DataFrame\n",
    "      - Column 'sequence_id': unique identifier for each sequence\n",
    "      - 'gesture': one of the eight target gestures or \"Non-Target\"\n",
    "\n",
    "    This metric averages:\n",
    "    1. Binary F1 on SequenceType (Target vs Non-Target)\n",
    "    2. Macro F1 on gesture (mapping non-targets to \"Non-Target\")\n",
    "\n",
    "    Raises ParticipantVisibleError for invalid submissions,\n",
    "    including invalid SequenceType or gesture values.\n",
    "\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> solution = pd.DataFrame({'id': range(4), 'gesture': ['Eyebrow - pull hair']*4})\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Forehead - pull hairline']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.5\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Text on phone']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.0\n",
    "    >>> score(solution, solution, row_id_column_name=row_id_column_name)\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    # Validate required columns\n",
    "    for col in (row_id_column_name, 'gesture'):\n",
    "        if col not in solution.columns:\n",
    "            raise ParticipantVisibleError(f\"Solution file missing required column: '{col}'\")\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f\"Submission file missing required column: '{col}'\")\n",
    "\n",
    "    metric = CompetitionMetric()\n",
    "    return metric.calculate_hierarchical_f1(solution, submission)\n",
    "\n",
    "# metric = CompetitionMetric()\n",
    "# score = metric.calculate_hierarchical_f1(y_true, y_pred)\n",
    "# print(f\"Estimated leaderboard (val) score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce533622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T16:51:40.308932Z",
     "iopub.status.busy": "2025-06-09T16:51:40.308586Z",
     "iopub.status.idle": "2025-06-09T16:51:43.156618Z",
     "shell.execute_reply": "2025-06-09T16:51:43.154995Z"
    },
    "papermill": {
     "duration": 2.858663,
     "end_time": "2025-06-09T16:51:43.162449",
     "exception": false,
     "start_time": "2025-06-09T16:51:40.303786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features.to_csv(\"train_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 203.170552,
   "end_time": "2025-06-09T16:51:44.196829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T16:48:21.026277",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
