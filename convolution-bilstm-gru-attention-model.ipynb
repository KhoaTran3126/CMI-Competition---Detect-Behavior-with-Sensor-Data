{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23c1de4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:12.356838Z",
     "iopub.status.busy": "2025-06-20T18:15:12.356637Z",
     "iopub.status.idle": "2025-06-20T18:15:19.685892Z",
     "shell.execute_reply": "2025-06-20T18:15:19.685280Z"
    },
    "papermill": {
     "duration": 7.336202,
     "end_time": "2025-06-20T18:15:19.687177",
     "exception": false,
     "start_time": "2025-06-20T18:15:12.350975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99feec7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:19.696374Z",
     "iopub.status.busy": "2025-06-20T18:15:19.696065Z",
     "iopub.status.idle": "2025-06-20T18:15:19.778240Z",
     "shell.execute_reply": "2025-06-20T18:15:19.777688Z"
    },
    "papermill": {
     "duration": 0.087664,
     "end_time": "2025-06-20T18:15:19.779225",
     "exception": false,
     "start_time": "2025-06-20T18:15:19.691561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95\n",
    "PAD_LEN = 127\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4\n",
    "EPOCHS = 300\n",
    "PATIENCE = 15\n",
    "SEED = 3126\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fe2132",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:19.788059Z",
     "iopub.status.busy": "2025-06-20T18:15:19.787839Z",
     "iopub.status.idle": "2025-06-20T18:15:19.858817Z",
     "shell.execute_reply": "2025-06-20T18:15:19.858309Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.076536,
     "end_time": "2025-06-20T18:15:19.859877",
     "exception": false,
     "start_time": "2025-06-20T18:15:19.783341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        \n",
    "        f1_binary = f1_score(y_true_bin, y_pred_bin, pos_label=True, zero_division=0, average='binary')\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        f1_macro = f1_score(y_true_mc, y_pred_mc, average='macro', zero_division=0)\n",
    "\n",
    "        return f1_binary, f1_macro, (f1_binary+f1_macro)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "248ecf6a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:19.868484Z",
     "iopub.status.busy": "2025-06-20T18:15:19.868109Z",
     "iopub.status.idle": "2025-06-20T18:15:19.872863Z",
     "shell.execute_reply": "2025-06-20T18:15:19.872197Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010071,
     "end_time": "2025-06-20T18:15:19.873893",
     "exception": false,
     "start_time": "2025-06-20T18:15:19.863822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def F1_score(y_val, y_pred, lbl_encoder, choice=\"weighted\"):\n",
    "    metric = CompetitionMetric()\n",
    "    y_val  = pd.DataFrame({'id':range(len(y_val)), \n",
    "                           'gesture':y_val})\n",
    "    y_pred = pd.DataFrame({'id':range(len(y_pred)), \n",
    "                           'gesture':y_pred})\n",
    "\n",
    "    ## Convert numeric labels to original descriptions\n",
    "    y_val[\"gesture\"]  = lbl_encoder.inverse_transform(y_val[\"gesture\"])\n",
    "    y_pred[\"gesture\"] = lbl_encoder.inverse_transform(y_pred[\"gesture\"])\n",
    "\n",
    "    ## Computes score\n",
    "    binary, macro, weighted = metric.calculate_hierarchical_f1(y_val, y_pred)\n",
    "\n",
    "    ## Returns result\n",
    "    if choice==\"binary\": return binary\n",
    "    elif choice==\"macro\": return macro\n",
    "    elif choice==\"weighted\": return weighted\n",
    "    else: return (binary, macro, weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad69b334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:19.882134Z",
     "iopub.status.busy": "2025-06-20T18:15:19.881936Z",
     "iopub.status.idle": "2025-06-20T18:15:19.890401Z",
     "shell.execute_reply": "2025-06-20T18:15:19.889755Z"
    },
    "papermill": {
     "duration": 0.013705,
     "end_time": "2025-06-20T18:15:19.891407",
     "exception": false,
     "start_time": "2025-06-20T18:15:19.877702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_all(seed=3126):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(SEED + worker_id)\n",
    "    random.seed(SEED + worker_id)\n",
    "\n",
    "seed_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa548c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:19.899539Z",
     "iopub.status.busy": "2025-06-20T18:15:19.899342Z",
     "iopub.status.idle": "2025-06-20T18:15:21.657213Z",
     "shell.execute_reply": "2025-06-20T18:15:21.656676Z"
    },
    "papermill": {
     "duration": 1.763371,
     "end_time": "2025-06-20T18:15:21.658454",
     "exception": false,
     "start_time": "2025-06-20T18:15:19.895083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAW_DIR = \"/kaggle/input/cmi-detect-behavior-with-sensor-data\"\n",
    "\n",
    "label_encoder = joblib.load(\"/kaggle/input/cmi-label-encoder/label_encoder.joblib\")\n",
    "standard_scaler = joblib.load(\"/kaggle/input/custom-tensor-data-v1/StandardScaler.joblib\")\n",
    "X = torch.load(\"/kaggle/input/custom-tensor-data-v1/X.pt\")\n",
    "y_int = np.load(\"/kaggle/input/custom-tensor-data-v1/y_int.npy\")\n",
    "y_ohe = torch.load(\"/kaggle/input/custom-tensor-data-v1/y.pt\")\n",
    "\n",
    "imu_cols = joblib.load(\"/kaggle/input/custom-tensor-data-v1/imu_cols.joblib\")\n",
    "thm_tof_cols = joblib.load(\"/kaggle/input/custom-tensor-data-v1/thm_tof_cols.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1385cf84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.667696Z",
     "iopub.status.busy": "2025-06-20T18:15:21.667447Z",
     "iopub.status.idle": "2025-06-20T18:15:21.671444Z",
     "shell.execute_reply": "2025-06-20T18:15:21.670835Z"
    },
    "papermill": {
     "duration": 0.009578,
     "end_time": "2025-06-20T18:15:21.672466",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.662888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU Features:\n",
      "['acc_x', 'acc_y', 'acc_z', 'acc_x_diff', 'acc_y_diff', 'acc_z_diff', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'acc_mag', 'rot_angle', 'acc_mag_diff', 'rot_angle_diff']\n",
      "\n",
      "\n",
      "Thm+TOF Features:\n",
      "['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'thm_1_diff', 'thm_2_diff', 'thm_3_diff', 'thm_4_diff', 'thm_5_diff', 'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max', 'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max', 'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max']\n"
     ]
    }
   ],
   "source": [
    "print(\"IMU Features:\")\n",
    "print(imu_cols)\n",
    "print(\"\\n\\nThm+TOF Features:\")\n",
    "print(thm_tof_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234080d0",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2025-06-20T18:15:21.680105",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.676405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87b227f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.688931Z",
     "iopub.status.busy": "2025-06-20T18:15:21.688308Z",
     "iopub.status.idle": "2025-06-20T18:15:21.693673Z",
     "shell.execute_reply": "2025-06-20T18:15:21.693132Z"
    },
    "papermill": {
     "duration": 0.010765,
     "end_time": "2025-06-20T18:15:21.694747",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.683982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SqueezeExcitation(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation (SE) block.\n",
    "    Input expected in (batch_size, timesteps, channels) format.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=8):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1) # (batch_size, channels, 1)\n",
    "        self.reduced_channels = max(8, channels // reduction)\n",
    "        \n",
    "        self.se = nn.Sequential(\n",
    "            nn.Conv1d(channels, self.reduced_channels, kernel_size=1, bias=False),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv1d(self.reduced_channels, channels, kernel_size=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, timesteps, channels) -> (B, T, C)\n",
    "        x_perm = x.permute(0, 2, 1)           # (B, C, T)\n",
    "        pooled = self.avg_pool(x_perm)        # (B, C, 1)\n",
    "        weights = self.se(pooled)             # (B, C, 1)\n",
    "        out = x_perm * weights                # (B, C, T)\n",
    "        return out.permute(0, 2, 1)           # (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d223c38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.703388Z",
     "iopub.status.busy": "2025-06-20T18:15:21.702837Z",
     "iopub.status.idle": "2025-06-20T18:15:21.709922Z",
     "shell.execute_reply": "2025-06-20T18:15:21.709217Z"
    },
    "papermill": {
     "duration": 0.012488,
     "end_time": "2025-06-20T18:15:21.710997",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.698509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualSECNNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual CNN Block with Squeeze-and-Excitation (SE)\n",
    "    Input expected in (batch_size, timesteps, channels) format.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, pool_size=2, drop=0.3):\n",
    "        super(ResidualSECNNBlock, self).__init__()\n",
    "        # PyTorch Conv1D expects (batch_size, channels, timesteps)\n",
    "\n",
    "        ## CNN model\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        ## Squeeze-Excitation module\n",
    "        self.se_block = SqueezeExcitation(out_channels)\n",
    "\n",
    "        self.shortcut_proj = None\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut_proj = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, padding='same', bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.relu_final = nn.ReLU(inplace=True)\n",
    "        if pool_size is not None: \n",
    "            self.max_pool = nn.MaxPool1d(pool_size)\n",
    "        else: \n",
    "            self.max_pool = None\n",
    "        self.dropout = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x                                      # (B, T, C_in)\n",
    "        x_permuted = self.cnn(x.permute(0, 2, 1))         # (B, C_out, T)\n",
    "        x_se = self.se_block(x_permuted.permute(0, 2, 1)) # (B, T, C_out)\n",
    "\n",
    "        # Handle shortcut connection\n",
    "        if self.shortcut_proj:\n",
    "            shortcut = self.shortcut_proj(shortcut.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "        # Residual connection\n",
    "        x = self.relu_final(x_se + shortcut)\n",
    "        if self.max_pool is not None:\n",
    "            x = self.max_pool(x.permute(0, 2, 1)).permute(0, 2, 1) # (B, T, C_out) -> (B, T//pool_size, C_out)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a32024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.719628Z",
     "iopub.status.busy": "2025-06-20T18:15:21.719064Z",
     "iopub.status.idle": "2025-06-20T18:15:21.723431Z",
     "shell.execute_reply": "2025-06-20T18:15:21.722954Z"
    },
    "papermill": {
     "duration": 0.009526,
     "end_time": "2025-06-20T18:15:21.724387",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.714861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention mechanism to weigh the importance of different timesteps.\n",
    "    Input expected in (batch_size, timesteps, features) format.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dim):\n",
    "        super(MLPAttention, self).__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim//8),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(feature_dim//8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs shape: (B, T, C)\n",
    "        score = self.attn(inputs).squeeze(-1) # (B, T)\n",
    "        weights = F.softmax(score, dim=-1).unsqueeze(-1) # (B, T, 1)\n",
    "        context = (inputs * weights).sum(dim=1) # (B, T, C) -> (B, C)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb74b703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.732930Z",
     "iopub.status.busy": "2025-06-20T18:15:21.732728Z",
     "iopub.status.idle": "2025-06-20T18:15:21.742915Z",
     "shell.execute_reply": "2025-06-20T18:15:21.742206Z"
    },
    "papermill": {
     "duration": 0.015787,
     "end_time": "2025-06-20T18:15:21.744006",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.728219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoBranchModel(nn.Module):\n",
    "    def __init__(self, pad_len, imu_dim, thm_tof_dim, n_classes=18):\n",
    "        super(TwoBranchModel, self).__init__()\n",
    "        self.imu_dim = imu_dim\n",
    "        self.thm_tof_dim = thm_tof_dim\n",
    "        \n",
    "        # --- IMU Deep Branch ---\n",
    "        # (B, T, IMU dim) --> --> (B, T/4, 128)\n",
    "        self.imu_branch = nn.Sequential(\n",
    "            ResidualSECNNBlock(imu_dim, 64, kernel_size=3, pool_size=2, drop=0.1), # Output shape: (B, T/2, 64)\n",
    "            ResidualSECNNBlock(64, 64, kernel_size=3, pool_size=None, drop=0.1), # Output shape: (B, T/2, 64)\n",
    "            ResidualSECNNBlock(64, 128, kernel_size=5, pool_size=2, drop=0.1) # Output shape: (B, T/4, 128)\n",
    "        )\n",
    "\n",
    "        # --- Thm/TOF Lighter Branch ---\n",
    "        # (B, T, Thm+TOF dim) --> (B, T/4, 128)\n",
    "        self.thm_tof_branch = nn.Sequential(\n",
    "            nn.Conv1d(thm_tof_dim, 64, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv1d(64, 64, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(64, 128, 3, padding='same', bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2)  \n",
    "        )\n",
    "\n",
    "        # --- Merged Branch and Recurrent Layers ---\n",
    "        # Merged dimension: 128 (IMU) + 128 (Thm + TOF) = 256\n",
    "        merged_feature_dim = 128 + 128\n",
    "        self.lstm = nn.LSTM(merged_feature_dim, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "        self.gru  = nn.GRU(merged_feature_dim, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Output of bidirectional LSTM/GRU will be 2 * hidden_size\n",
    "        # (batch_size, timesteps_after_pooling, 2 * 128) = (batch_size, pad_len/4, 256)\n",
    "\n",
    "        # For x_merged path\n",
    "        self.gaussian_noise_std = 0.09 \n",
    "        self.dense = nn.Linear(merged_feature_dim, 16)\n",
    "        self.elu   = nn.ELU()\n",
    "        \n",
    "        # Concatenated features \n",
    "        # x_gru: (B, T, 256)\n",
    "        # x_lstm: (B, T, 256)\n",
    "        # x_merged: (B, T, 16)\n",
    "        self.concat_dropout = nn.Dropout(0.4)\n",
    "        self.attention_layer = MLPAttention(528)\n",
    "\n",
    "        # --- Classification Head ---\n",
    "        # After attention, shape is (B, 528)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(528, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(128, n_classes)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x_imu     = inp[:, :, :self.imu_dim] # (B, T, IMU dim)\n",
    "        x_thm_tof = inp[:, :, self.imu_dim:] # (B, T, Thm + TOF dim)\n",
    "\n",
    "        # --- IMU Deep Branch ---\n",
    "        x_imu = self.imu_branch(x_imu) # (B, T/4, 128)\n",
    "\n",
    "        # --- TOF/Thermal Lighter Branch ---\n",
    "        x_thm_tof = self.thm_tof_branch(x_thm_tof.permute(0, 2, 1)) \n",
    "        x_thm_tof = x_thm_tof.permute(0, 2, 1) # (B, T/4, 128)\n",
    "\n",
    "        # --- Merge Branches ---\n",
    "        merged = torch.cat([x_imu, x_thm_tof], dim=-1) # (B, T/4, 256)\n",
    "\n",
    "        # --- Recurrent Layers ---\n",
    "        x_lstm, _ = self.lstm(merged) # (B, T/4, 256)\n",
    "        x_gru, _  = self.gru(merged)  # (B, T/4, 256)\n",
    "        \n",
    "        # x_merged path (gaussian noise)\n",
    "        if self.training: \n",
    "            x_merged = merged + torch.randn_like(merged)*self.gaussian_noise_std\n",
    "        else:\n",
    "            x_merged = merged\n",
    "        x_merged = self.elu(self.dense(x_merged)) # (B, T/4, 16)\n",
    "\n",
    "        # Concatenate outputs of all three paths\n",
    "        x = torch.cat([x_lstm, x_gru, x_merged], dim=-1) # (B, T/4, 256*2 + 16) = (B, T/4, 528)\n",
    "        x = self.concat_dropout(x)\n",
    "\n",
    "        # Attention layer\n",
    "        x = self.attention_layer(x) # Output: (B, 528)\n",
    "\n",
    "        # --- Classification Head ---\n",
    "        x = self.classifier(x)\n",
    "        out = self.output_layer(x) # (B, 18)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05dd7517",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.752584Z",
     "iopub.status.busy": "2025-06-20T18:15:21.752392Z",
     "iopub.status.idle": "2025-06-20T18:15:21.757259Z",
     "shell.execute_reply": "2025-06-20T18:15:21.756766Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01004,
     "end_time": "2025-06-20T18:15:21.758218",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.748178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_model_weights(model:nn.Module):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv1d)):\n",
    "            nn.init.kaiming_uniform_(module.weight, nonlinearity=\"relu\")\n",
    "            \n",
    "        elif isinstance(module, (nn.LSTM, nn.GRU)):\n",
    "            for name, param in module.named_parameters():\n",
    "                if 'weight_ih' in name: \n",
    "                    nn.init.xavier_uniform_(param.data)\n",
    "                elif 'weight_hh' in name: \n",
    "                    nn.init.orthogonal_(param.data) \n",
    "                elif 'bias_ih' in name or 'bias_hh' in name: \n",
    "                    nn.init.constant_(param.data, 0)\n",
    "                    if 'bias_ih' in name and isinstance(module, nn.LSTM):\n",
    "                        nn.init.constant_(param.data[module.hidden_size : 2 * module.hidden_size], 1.0)\n",
    "        \n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f4298ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.766320Z",
     "iopub.status.busy": "2025-06-20T18:15:21.766153Z",
     "iopub.status.idle": "2025-06-20T18:15:21.771315Z",
     "shell.execute_reply": "2025-06-20T18:15:21.770813Z"
    },
    "papermill": {
     "duration": 0.010258,
     "end_time": "2025-06-20T18:15:21.772246",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.761988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MixupDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, alpha: float = 0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (np.ndarray): Features (e.g., padded time series data).\n",
    "                            Expected shape (num_samples, timesteps, features).\n",
    "            y (np.ndarray): Labels (e.g., one-hot encoded or class indices).\n",
    "                            Expected shape (num_samples, num_classes) for one-hot,\n",
    "                            or (num_samples,) for class indices.\n",
    "            alpha (float): Alpha parameter for the Beta distribution used in Mixup.\n",
    "        \"\"\"\n",
    "        # Convert X and y to PyTorch tensors once\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32 if (y.ndim>1) else (torch.long)) # Use long for class indices\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data for Mixup.\n",
    "        \"\"\"\n",
    "        x, y = self.X[idx], self.y[idx]\n",
    "        \n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            rand_idx = np.random.randint(0, len(self.X))\n",
    "            x_rand, y_rand = self.X[rand_idx], self.y[rand_idx]\n",
    "            \n",
    "            x = lam * x + (1 - lam) * x_rand\n",
    "            y = lam * y + (1 - lam) * y_rand\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6066bcc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.781276Z",
     "iopub.status.busy": "2025-06-20T18:15:21.781089Z",
     "iopub.status.idle": "2025-06-20T18:15:21.785121Z",
     "shell.execute_reply": "2025-06-20T18:15:21.784411Z"
    },
    "papermill": {
     "duration": 0.009789,
     "end_time": "2025-06-20T18:15:21.786145",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.776356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def label_smoothing_loss(pred, target, smoothing=0.1):\n",
    "    \"\"\"Label smoothing loss\"\"\"\n",
    "    confidence = 1.0 - smoothing\n",
    "    log_probs = F.log_softmax(pred, dim=-1)\n",
    "    nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "    nll_loss = nll_loss.squeeze(1)\n",
    "    smooth_loss = -log_probs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401fff60",
   "metadata": {
    "papermill": {
     "duration": 0.003572,
     "end_time": "2025-06-20T18:15:21.793507",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.789935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "466e75b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.801845Z",
     "iopub.status.busy": "2025-06-20T18:15:21.801676Z",
     "iopub.status.idle": "2025-06-20T18:15:21.813810Z",
     "shell.execute_reply": "2025-06-20T18:15:21.813127Z"
    },
    "papermill": {
     "duration": 0.017441,
     "end_time": "2025-06-20T18:15:21.814859",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.797418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ec4168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:21.822947Z",
     "iopub.status.busy": "2025-06-20T18:15:21.822776Z",
     "iopub.status.idle": "2025-06-20T18:15:22.172309Z",
     "shell.execute_reply": "2025-06-20T18:15:22.171705Z"
    },
    "papermill": {
     "duration": 0.354987,
     "end_time": "2025-06-20T18:15:22.173541",
     "exception": false,
     "start_time": "2025-06-20T18:15:21.818554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X.numpy(), y_ohe.numpy(), \n",
    "        test_size=0.2, random_state=SEED, stratify=y_int\n",
    ")\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "\n",
    "cw_vals = compute_class_weight('balanced', \n",
    "                               classes=np.arange(len(label_encoder.classes_)),\n",
    "                               y=y_int)\n",
    "class_weights = torch.FloatTensor(cw_vals).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54921932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:22.182881Z",
     "iopub.status.busy": "2025-06-20T18:15:22.182369Z",
     "iopub.status.idle": "2025-06-20T18:15:22.257371Z",
     "shell.execute_reply": "2025-06-20T18:15:22.256608Z"
    },
    "papermill": {
     "duration": 0.080923,
     "end_time": "2025-06-20T18:15:22.258813",
     "exception": false,
     "start_time": "2025-06-20T18:15:22.177890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_dataset = MixupDataset(X_train, y_train, alpha=MIXUP_ALPHA)\n",
    "val_dataset = MixupDataset(X_val, y_val, alpha=0.0)  \n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6d76ec",
   "metadata": {
    "papermill": {
     "duration": 0.004769,
     "end_time": "2025-06-20T18:15:22.268782",
     "exception": false,
     "start_time": "2025-06-20T18:15:22.264013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc49622a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:22.277339Z",
     "iopub.status.busy": "2025-06-20T18:15:22.276946Z",
     "iopub.status.idle": "2025-06-20T18:15:27.099699Z",
     "shell.execute_reply": "2025-06-20T18:15:27.099107Z"
    },
    "papermill": {
     "duration": 4.828361,
     "end_time": "2025-06-20T18:15:27.101060",
     "exception": false,
     "start_time": "2025-06-20T18:15:22.272699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TwoBranchModel(PAD_LEN, len(imu_cols), len(thm_tof_cols)).to(DEVICE)\n",
    "init_model_weights(model)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR_INIT, weight_decay=WD)\n",
    "\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5*steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76df2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:27.110075Z",
     "iopub.status.busy": "2025-06-20T18:15:27.109753Z",
     "iopub.status.idle": "2025-06-20T18:15:27.114312Z",
     "shell.execute_reply": "2025-06-20T18:15:27.113812Z"
    },
    "papermill": {
     "duration": 0.010054,
     "end_time": "2025-06-20T18:15:27.115284",
     "exception": false,
     "start_time": "2025-06-20T18:15:27.105230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class F1EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_f1 = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, model, current_f1):\n",
    "        if current_f1 > self.best_f1:\n",
    "            self.best_f1 = current_f1\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"F1 EarlyStopping: {self.counter}/{self.patience}\\n\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "125dc985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:27.123846Z",
     "iopub.status.busy": "2025-06-20T18:15:27.123632Z",
     "iopub.status.idle": "2025-06-20T18:15:27.129394Z",
     "shell.execute_reply": "2025-06-20T18:15:27.128890Z"
    },
    "papermill": {
     "duration": 0.011007,
     "end_time": "2025-06-20T18:15:27.130354",
     "exception": false,
     "start_time": "2025-06-20T18:15:27.119347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, class_weights, lr_scheduler=None):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "        \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "                    \n",
    "        logits = model(batch_x)\n",
    "                    \n",
    "        # Handle mixup targets\n",
    "        if batch_y.ndim == 2 and batch_y.shape[1] > 1:  # MixUp or one-hot\n",
    "            sample_weights = torch.sum(batch_y * class_weights.unsqueeze(0), dim=1)\n",
    "            log_probs = F.log_softmax(logits, dim=1)\n",
    "            loss_vec = -torch.sum(log_probs * batch_y, dim=1)  # (B,)\n",
    "            loss = (loss_vec * sample_weights).mean()\n",
    "            targets = batch_y.argmax(dim=1)\n",
    "        else:\n",
    "            targets = batch_y.long()\n",
    "            loss = label_smoothing_loss(logits, targets, smoothing=0.1)            \n",
    "        \n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ## Accmulate loss and accuracy\n",
    "        total_loss += loss.item() * batch_x.size(0)\n",
    "        total_correct += (logits.argmax(dim=1) == targets).sum().item()\n",
    "        total_samples += batch_x.size(0)\n",
    "        \n",
    "    if lr_scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    ## Normalize loss and accuracy\n",
    "    train_loss = total_loss/total_samples\n",
    "    train_acc  = total_correct/total_samples\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abf04f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:27.139783Z",
     "iopub.status.busy": "2025-06-20T18:15:27.139542Z",
     "iopub.status.idle": "2025-06-20T18:15:27.145064Z",
     "shell.execute_reply": "2025-06-20T18:15:27.144522Z"
    },
    "papermill": {
     "duration": 0.010696,
     "end_time": "2025-06-20T18:15:27.146035",
     "exception": false,
     "start_time": "2025-06-20T18:15:27.135339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, lbl_encoder):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_correct, total_samples = 0, 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(DEVICE), batch_y.to(DEVICE)\n",
    "            logits = model(batch_x)\n",
    "\n",
    "            # For both loss and metrics, assume batch_y is one-hot or integer labels\n",
    "            if batch_y.ndim == 2:\n",
    "                targets = batch_y.argmax(dim=1)\n",
    "            else:\n",
    "                targets = batch_y\n",
    "\n",
    "            # Computes loss and predictions\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            # Track batch metrics\n",
    "            val_loss += loss.item() * batch_x.size(0)\n",
    "            total_correct += (preds == targets).sum().item()\n",
    "            total_samples += batch_x.size(0)\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "    # Stack all predictions and targets\n",
    "    y_pred_all = torch.cat(all_preds).numpy()\n",
    "    y_val_all  = torch.cat(all_targets).numpy()\n",
    "\n",
    "    # Compute custom hierarchical F1\n",
    "    val_f1 = F1_score(y_val_all, y_pred_all, lbl_encoder, choice=\"weighted\")\n",
    "    val_loss = val_loss / total_samples\n",
    "    val_acc  = total_correct / total_samples\n",
    "\n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd54d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:27.154314Z",
     "iopub.status.busy": "2025-06-20T18:15:27.154119Z",
     "iopub.status.idle": "2025-06-20T18:15:27.159447Z",
     "shell.execute_reply": "2025-06-20T18:15:27.158940Z"
    },
    "papermill": {
     "duration": 0.010454,
     "end_time": "2025-06-20T18:15:27.160337",
     "exception": false,
     "start_time": "2025-06-20T18:15:27.149883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval(epochs, model, train_loader, val_loader, optimizer, class_weights, lbl_encoder, lr_scheduler=None):\n",
    "    train_losses, train_accuracies = [], []\n",
    "    val_losses, val_accuracies = [], []\n",
    "    val_F1 = []\n",
    "    history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        ## Trains model\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, class_weights, lr_scheduler)\n",
    "\n",
    "        ## Evaluates model\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, lbl_encoder)\n",
    "\n",
    "        ## Append metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_F1.append(val_f1)\n",
    "\n",
    "        ## Checks early stopping\n",
    "        if early_stopper is not None:\n",
    "            early_stopper(model, val_f1)\n",
    "            if early_stopper.early_stop:\n",
    "                print(f\"\\nEarly stopping triggered at epoch {epoch+1}\\n\")\n",
    "                break\n",
    "                \n",
    "        ## Displays any result\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "        print(f\"Train Accuracy: {train_acc:.3f}     Train Loss: {train_loss:.3f}\")\n",
    "        print(f\"Val Accuracy:   {val_acc:.3f}       Val F1:     {val_f1:.2f}     Val Loss:   {val_loss:.3f}\\n\")\n",
    "\n",
    "    ## Save results to history dictionary\n",
    "    history[\"train_losses\"] = train_losses\n",
    "    history[\"train_accuracies\"] = train_accuracies\n",
    "    history[\"val_losses\"] = val_losses\n",
    "    history[\"val_accuracies\"] = val_accuracies\n",
    "    history[\"val_F1\"] = val_F1\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77452ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:15:27.168671Z",
     "iopub.status.busy": "2025-06-20T18:15:27.168465Z",
     "iopub.status.idle": "2025-06-20T18:40:01.509443Z",
     "shell.execute_reply": "2025-06-20T18:40:01.508342Z"
    },
    "papermill": {
     "duration": 1474.346748,
     "end_time": "2025-06-20T18:40:01.510928",
     "exception": false,
     "start_time": "2025-06-20T18:15:27.164180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300]\n",
      "Train Accuracy: 0.140     Train Loss: 2.844\n",
      "Val Accuracy:   0.340       Val F1:     0.56     Val Loss:   2.054\n",
      "\n",
      "Epoch [2/300]\n",
      "Train Accuracy: 0.263     Train Loss: 2.316\n",
      "Val Accuracy:   0.412       Val F1:     0.63     Val Loss:   1.753\n",
      "\n",
      "Epoch [3/300]\n",
      "Train Accuracy: 0.336     Train Loss: 2.126\n",
      "Val Accuracy:   0.469       Val F1:     0.66     Val Loss:   1.567\n",
      "\n",
      "Epoch [4/300]\n",
      "Train Accuracy: 0.394     Train Loss: 1.962\n",
      "Val Accuracy:   0.495       Val F1:     0.67     Val Loss:   1.443\n",
      "\n",
      "Epoch [5/300]\n",
      "Train Accuracy: 0.427     Train Loss: 1.885\n",
      "Val Accuracy:   0.516       Val F1:     0.70     Val Loss:   1.337\n",
      "\n",
      "Epoch [6/300]\n",
      "Train Accuracy: 0.448     Train Loss: 1.831\n",
      "Val Accuracy:   0.541       Val F1:     0.71     Val Loss:   1.287\n",
      "\n",
      "Epoch [7/300]\n",
      "Train Accuracy: 0.481     Train Loss: 1.746\n",
      "Val Accuracy:   0.563       Val F1:     0.72     Val Loss:   1.220\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [8/300]\n",
      "Train Accuracy: 0.497     Train Loss: 1.704\n",
      "Val Accuracy:   0.559       Val F1:     0.72     Val Loss:   1.197\n",
      "\n",
      "Epoch [9/300]\n",
      "Train Accuracy: 0.523     Train Loss: 1.658\n",
      "Val Accuracy:   0.582       Val F1:     0.73     Val Loss:   1.140\n",
      "\n",
      "Epoch [10/300]\n",
      "Train Accuracy: 0.529     Train Loss: 1.631\n",
      "Val Accuracy:   0.590       Val F1:     0.74     Val Loss:   1.103\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [11/300]\n",
      "Train Accuracy: 0.546     Train Loss: 1.603\n",
      "Val Accuracy:   0.586       Val F1:     0.74     Val Loss:   1.127\n",
      "\n",
      "Epoch [12/300]\n",
      "Train Accuracy: 0.550     Train Loss: 1.586\n",
      "Val Accuracy:   0.601       Val F1:     0.75     Val Loss:   1.079\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [13/300]\n",
      "Train Accuracy: 0.571     Train Loss: 1.529\n",
      "Val Accuracy:   0.606       Val F1:     0.75     Val Loss:   1.074\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [14/300]\n",
      "Train Accuracy: 0.566     Train Loss: 1.517\n",
      "Val Accuracy:   0.602       Val F1:     0.74     Val Loss:   1.082\n",
      "\n",
      "Epoch [15/300]\n",
      "Train Accuracy: 0.583     Train Loss: 1.483\n",
      "Val Accuracy:   0.628       Val F1:     0.77     Val Loss:   1.013\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [16/300]\n",
      "Train Accuracy: 0.597     Train Loss: 1.449\n",
      "Val Accuracy:   0.617       Val F1:     0.75     Val Loss:   1.024\n",
      "\n",
      "Epoch [17/300]\n",
      "Train Accuracy: 0.596     Train Loss: 1.450\n",
      "Val Accuracy:   0.640       Val F1:     0.78     Val Loss:   0.986\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [18/300]\n",
      "Train Accuracy: 0.615     Train Loss: 1.410\n",
      "Val Accuracy:   0.636       Val F1:     0.77     Val Loss:   1.003\n",
      "\n",
      "Epoch [19/300]\n",
      "Train Accuracy: 0.621     Train Loss: 1.407\n",
      "Val Accuracy:   0.652       Val F1:     0.78     Val Loss:   0.946\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [20/300]\n",
      "Train Accuracy: 0.635     Train Loss: 1.379\n",
      "Val Accuracy:   0.643       Val F1:     0.77     Val Loss:   0.973\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [21/300]\n",
      "Train Accuracy: 0.631     Train Loss: 1.387\n",
      "Val Accuracy:   0.647       Val F1:     0.78     Val Loss:   0.952\n",
      "\n",
      "Epoch [22/300]\n",
      "Train Accuracy: 0.650     Train Loss: 1.349\n",
      "Val Accuracy:   0.660       Val F1:     0.79     Val Loss:   0.923\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [23/300]\n",
      "Train Accuracy: 0.648     Train Loss: 1.343\n",
      "Val Accuracy:   0.650       Val F1:     0.79     Val Loss:   0.940\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [24/300]\n",
      "Train Accuracy: 0.657     Train Loss: 1.337\n",
      "Val Accuracy:   0.638       Val F1:     0.77     Val Loss:   0.968\n",
      "\n",
      "Epoch [25/300]\n",
      "Train Accuracy: 0.666     Train Loss: 1.320\n",
      "Val Accuracy:   0.668       Val F1:     0.79     Val Loss:   0.921\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [26/300]\n",
      "Train Accuracy: 0.671     Train Loss: 1.310\n",
      "Val Accuracy:   0.657       Val F1:     0.79     Val Loss:   0.922\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [27/300]\n",
      "Train Accuracy: 0.674     Train Loss: 1.313\n",
      "Val Accuracy:   0.658       Val F1:     0.79     Val Loss:   0.940\n",
      "\n",
      "Epoch [28/300]\n",
      "Train Accuracy: 0.672     Train Loss: 1.290\n",
      "Val Accuracy:   0.679       Val F1:     0.80     Val Loss:   0.906\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [29/300]\n",
      "Train Accuracy: 0.678     Train Loss: 1.304\n",
      "Val Accuracy:   0.646       Val F1:     0.79     Val Loss:   0.957\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [30/300]\n",
      "Train Accuracy: 0.681     Train Loss: 1.277\n",
      "Val Accuracy:   0.668       Val F1:     0.79     Val Loss:   0.883\n",
      "\n",
      "Epoch [31/300]\n",
      "Train Accuracy: 0.687     Train Loss: 1.257\n",
      "Val Accuracy:   0.685       Val F1:     0.80     Val Loss:   0.859\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [32/300]\n",
      "Train Accuracy: 0.698     Train Loss: 1.242\n",
      "Val Accuracy:   0.667       Val F1:     0.79     Val Loss:   0.881\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [33/300]\n",
      "Train Accuracy: 0.703     Train Loss: 1.230\n",
      "Val Accuracy:   0.673       Val F1:     0.80     Val Loss:   0.879\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [34/300]\n",
      "Train Accuracy: 0.700     Train Loss: 1.216\n",
      "Val Accuracy:   0.663       Val F1:     0.79     Val Loss:   0.899\n",
      "\n",
      "Epoch [35/300]\n",
      "Train Accuracy: 0.716     Train Loss: 1.204\n",
      "Val Accuracy:   0.684       Val F1:     0.81     Val Loss:   0.875\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [36/300]\n",
      "Train Accuracy: 0.718     Train Loss: 1.200\n",
      "Val Accuracy:   0.684       Val F1:     0.80     Val Loss:   0.861\n",
      "\n",
      "Epoch [37/300]\n",
      "Train Accuracy: 0.717     Train Loss: 1.202\n",
      "Val Accuracy:   0.690       Val F1:     0.81     Val Loss:   0.863\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [38/300]\n",
      "Train Accuracy: 0.723     Train Loss: 1.188\n",
      "Val Accuracy:   0.689       Val F1:     0.81     Val Loss:   0.856\n",
      "\n",
      "Epoch [39/300]\n",
      "Train Accuracy: 0.717     Train Loss: 1.179\n",
      "Val Accuracy:   0.693       Val F1:     0.81     Val Loss:   0.838\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [40/300]\n",
      "Train Accuracy: 0.730     Train Loss: 1.173\n",
      "Val Accuracy:   0.685       Val F1:     0.80     Val Loss:   0.858\n",
      "\n",
      "Epoch [41/300]\n",
      "Train Accuracy: 0.734     Train Loss: 1.149\n",
      "Val Accuracy:   0.693       Val F1:     0.81     Val Loss:   0.849\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [42/300]\n",
      "Train Accuracy: 0.740     Train Loss: 1.146\n",
      "Val Accuracy:   0.687       Val F1:     0.80     Val Loss:   0.859\n",
      "\n",
      "Epoch [43/300]\n",
      "Train Accuracy: 0.742     Train Loss: 1.145\n",
      "Val Accuracy:   0.693       Val F1:     0.81     Val Loss:   0.854\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [44/300]\n",
      "Train Accuracy: 0.746     Train Loss: 1.133\n",
      "Val Accuracy:   0.692       Val F1:     0.81     Val Loss:   0.859\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [45/300]\n",
      "Train Accuracy: 0.761     Train Loss: 1.109\n",
      "Val Accuracy:   0.686       Val F1:     0.80     Val Loss:   0.861\n",
      "\n",
      "Epoch [46/300]\n",
      "Train Accuracy: 0.748     Train Loss: 1.126\n",
      "Val Accuracy:   0.700       Val F1:     0.82     Val Loss:   0.833\n",
      "\n",
      "Epoch [47/300]\n",
      "Train Accuracy: 0.754     Train Loss: 1.112\n",
      "Val Accuracy:   0.693       Val F1:     0.82     Val Loss:   0.885\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [48/300]\n",
      "Train Accuracy: 0.756     Train Loss: 1.096\n",
      "Val Accuracy:   0.695       Val F1:     0.81     Val Loss:   0.847\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [49/300]\n",
      "Train Accuracy: 0.763     Train Loss: 1.110\n",
      "Val Accuracy:   0.682       Val F1:     0.81     Val Loss:   0.879\n",
      "\n",
      "Epoch [50/300]\n",
      "Train Accuracy: 0.763     Train Loss: 1.109\n",
      "Val Accuracy:   0.699       Val F1:     0.82     Val Loss:   0.846\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [51/300]\n",
      "Train Accuracy: 0.768     Train Loss: 1.086\n",
      "Val Accuracy:   0.693       Val F1:     0.81     Val Loss:   0.859\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [52/300]\n",
      "Train Accuracy: 0.762     Train Loss: 1.090\n",
      "Val Accuracy:   0.689       Val F1:     0.81     Val Loss:   0.860\n",
      "\n",
      "Epoch [53/300]\n",
      "Train Accuracy: 0.770     Train Loss: 1.086\n",
      "Val Accuracy:   0.715       Val F1:     0.83     Val Loss:   0.841\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [54/300]\n",
      "Train Accuracy: 0.775     Train Loss: 1.073\n",
      "Val Accuracy:   0.701       Val F1:     0.82     Val Loss:   0.847\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [55/300]\n",
      "Train Accuracy: 0.778     Train Loss: 1.067\n",
      "Val Accuracy:   0.709       Val F1:     0.82     Val Loss:   0.831\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [56/300]\n",
      "Train Accuracy: 0.779     Train Loss: 1.059\n",
      "Val Accuracy:   0.708       Val F1:     0.82     Val Loss:   0.856\n",
      "\n",
      "Epoch [57/300]\n",
      "Train Accuracy: 0.788     Train Loss: 1.036\n",
      "Val Accuracy:   0.723       Val F1:     0.83     Val Loss:   0.823\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [58/300]\n",
      "Train Accuracy: 0.786     Train Loss: 1.051\n",
      "Val Accuracy:   0.712       Val F1:     0.83     Val Loss:   0.839\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [59/300]\n",
      "Train Accuracy: 0.792     Train Loss: 1.035\n",
      "Val Accuracy:   0.715       Val F1:     0.83     Val Loss:   0.855\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [60/300]\n",
      "Train Accuracy: 0.787     Train Loss: 1.039\n",
      "Val Accuracy:   0.692       Val F1:     0.81     Val Loss:   0.904\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [61/300]\n",
      "Train Accuracy: 0.787     Train Loss: 1.041\n",
      "Val Accuracy:   0.711       Val F1:     0.82     Val Loss:   0.870\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [62/300]\n",
      "Train Accuracy: 0.798     Train Loss: 1.019\n",
      "Val Accuracy:   0.707       Val F1:     0.82     Val Loss:   0.878\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [63/300]\n",
      "Train Accuracy: 0.797     Train Loss: 1.030\n",
      "Val Accuracy:   0.709       Val F1:     0.82     Val Loss:   0.882\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [64/300]\n",
      "Train Accuracy: 0.801     Train Loss: 0.997\n",
      "Val Accuracy:   0.717       Val F1:     0.83     Val Loss:   0.896\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [65/300]\n",
      "Train Accuracy: 0.793     Train Loss: 1.014\n",
      "Val Accuracy:   0.713       Val F1:     0.83     Val Loss:   0.891\n",
      "\n",
      "F1 EarlyStopping: 9/15\n",
      "\n",
      "Epoch [66/300]\n",
      "Train Accuracy: 0.803     Train Loss: 1.004\n",
      "Val Accuracy:   0.719       Val F1:     0.83     Val Loss:   0.871\n",
      "\n",
      "F1 EarlyStopping: 10/15\n",
      "\n",
      "Epoch [67/300]\n",
      "Train Accuracy: 0.805     Train Loss: 1.001\n",
      "Val Accuracy:   0.716       Val F1:     0.83     Val Loss:   0.910\n",
      "\n",
      "F1 EarlyStopping: 11/15\n",
      "\n",
      "Epoch [68/300]\n",
      "Train Accuracy: 0.805     Train Loss: 1.003\n",
      "Val Accuracy:   0.711       Val F1:     0.83     Val Loss:   0.881\n",
      "\n",
      "F1 EarlyStopping: 12/15\n",
      "\n",
      "Epoch [69/300]\n",
      "Train Accuracy: 0.812     Train Loss: 0.989\n",
      "Val Accuracy:   0.714       Val F1:     0.83     Val Loss:   0.890\n",
      "\n",
      "F1 EarlyStopping: 13/15\n",
      "\n",
      "Epoch [70/300]\n",
      "Train Accuracy: 0.813     Train Loss: 0.989\n",
      "Val Accuracy:   0.711       Val F1:     0.83     Val Loss:   0.896\n",
      "\n",
      "F1 EarlyStopping: 14/15\n",
      "\n",
      "Epoch [71/300]\n",
      "Train Accuracy: 0.820     Train Loss: 0.977\n",
      "Val Accuracy:   0.705       Val F1:     0.82     Val Loss:   0.892\n",
      "\n",
      "Epoch [72/300]\n",
      "Train Accuracy: 0.821     Train Loss: 0.969\n",
      "Val Accuracy:   0.725       Val F1:     0.84     Val Loss:   0.893\n",
      "\n",
      "F1 EarlyStopping: 1/15\n",
      "\n",
      "Epoch [73/300]\n",
      "Train Accuracy: 0.821     Train Loss: 0.969\n",
      "Val Accuracy:   0.711       Val F1:     0.83     Val Loss:   0.897\n",
      "\n",
      "F1 EarlyStopping: 2/15\n",
      "\n",
      "Epoch [74/300]\n",
      "Train Accuracy: 0.820     Train Loss: 0.966\n",
      "Val Accuracy:   0.707       Val F1:     0.82     Val Loss:   0.901\n",
      "\n",
      "F1 EarlyStopping: 3/15\n",
      "\n",
      "Epoch [75/300]\n",
      "Train Accuracy: 0.823     Train Loss: 0.964\n",
      "Val Accuracy:   0.715       Val F1:     0.83     Val Loss:   0.881\n",
      "\n",
      "F1 EarlyStopping: 4/15\n",
      "\n",
      "Epoch [76/300]\n",
      "Train Accuracy: 0.823     Train Loss: 0.957\n",
      "Val Accuracy:   0.706       Val F1:     0.83     Val Loss:   0.923\n",
      "\n",
      "F1 EarlyStopping: 5/15\n",
      "\n",
      "Epoch [77/300]\n",
      "Train Accuracy: 0.820     Train Loss: 0.962\n",
      "Val Accuracy:   0.717       Val F1:     0.84     Val Loss:   0.938\n",
      "\n",
      "F1 EarlyStopping: 6/15\n",
      "\n",
      "Epoch [78/300]\n",
      "Train Accuracy: 0.827     Train Loss: 0.953\n",
      "Val Accuracy:   0.727       Val F1:     0.83     Val Loss:   0.846\n",
      "\n",
      "F1 EarlyStopping: 7/15\n",
      "\n",
      "Epoch [79/300]\n",
      "Train Accuracy: 0.833     Train Loss: 0.945\n",
      "Val Accuracy:   0.720       Val F1:     0.83     Val Loss:   0.872\n",
      "\n",
      "F1 EarlyStopping: 8/15\n",
      "\n",
      "Epoch [80/300]\n",
      "Train Accuracy: 0.823     Train Loss: 0.949\n",
      "Val Accuracy:   0.714       Val F1:     0.83     Val Loss:   0.878\n",
      "\n",
      "F1 EarlyStopping: 9/15\n",
      "\n",
      "Epoch [81/300]\n",
      "Train Accuracy: 0.835     Train Loss: 0.937\n",
      "Val Accuracy:   0.716       Val F1:     0.83     Val Loss:   0.898\n",
      "\n",
      "F1 EarlyStopping: 10/15\n",
      "\n",
      "Epoch [82/300]\n",
      "Train Accuracy: 0.831     Train Loss: 0.943\n",
      "Val Accuracy:   0.719       Val F1:     0.83     Val Loss:   0.887\n",
      "\n",
      "F1 EarlyStopping: 11/15\n",
      "\n",
      "Epoch [83/300]\n",
      "Train Accuracy: 0.834     Train Loss: 0.927\n",
      "Val Accuracy:   0.703       Val F1:     0.82     Val Loss:   0.959\n",
      "\n",
      "F1 EarlyStopping: 12/15\n",
      "\n",
      "Epoch [84/300]\n",
      "Train Accuracy: 0.828     Train Loss: 0.946\n",
      "Val Accuracy:   0.717       Val F1:     0.83     Val Loss:   0.901\n",
      "\n",
      "F1 EarlyStopping: 13/15\n",
      "\n",
      "Epoch [85/300]\n",
      "Train Accuracy: 0.837     Train Loss: 0.932\n",
      "Val Accuracy:   0.722       Val F1:     0.83     Val Loss:   0.898\n",
      "\n",
      "F1 EarlyStopping: 14/15\n",
      "\n",
      "Epoch [86/300]\n",
      "Train Accuracy: 0.842     Train Loss: 0.925\n",
      "Val Accuracy:   0.727       Val F1:     0.83     Val Loss:   0.888\n",
      "\n",
      "F1 EarlyStopping: 15/15\n",
      "\n",
      "\n",
      "Early stopping triggered at epoch 87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopper = F1EarlyStopping(PATIENCE, verbose=True)\n",
    "\n",
    "train_history = train_eval(\n",
    "    EPOCHS, \n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    optimizer, \n",
    "    class_weights, \n",
    "    label_encoder, \n",
    "    scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "308a0b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:40:01.527052Z",
     "iopub.status.busy": "2025-06-20T18:40:01.526809Z",
     "iopub.status.idle": "2025-06-20T18:40:01.535513Z",
     "shell.execute_reply": "2025-06-20T18:40:01.534996Z"
    },
    "papermill": {
     "duration": 0.017691,
     "end_time": "2025-06-20T18:40:01.536466",
     "exception": false,
     "start_time": "2025-06-20T18:40:01.518775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_history.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(train_history, \"train_history.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "sourceId": 245998721,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 246234309,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1495.783757,
   "end_time": "2025-06-20T18:40:04.100611",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-20T18:15:08.316854",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
